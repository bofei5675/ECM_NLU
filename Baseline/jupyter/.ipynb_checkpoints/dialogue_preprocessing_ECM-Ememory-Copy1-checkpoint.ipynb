{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:14.079320Z",
     "start_time": "2019-04-03T00:20:12.231583Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from preprocessing_dailydialogue import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:14.085039Z",
     "start_time": "2019-04-03T00:20:14.081116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define constant\n",
    "# Default word tokens\n",
    "#\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "USE_CUDA = False #torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "MAX_LENGTH = 25  # Maximum sentence length to consider\n",
    "MIN_COUNT = 1    # Minimum word count threshold for trimming\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "emo_dict = { 0: 'neutral', 1: 'joy', 2: 'anger', \n",
    "            3: 'sadness',4:'fear'}\n",
    "emo2idx = {value:key for key,value in emo_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data from pickle (No preprocessing required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('processed_train.pickle','rb') as f:\n",
    "    pairs = pickle.load(f)\n",
    "    pairs_emotion = pickle.load(f)\n",
    "    voc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = pairs[:1000]\n",
    "pairs_emotion = pairs_emotion[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.371122Z",
     "start_time": "2019-04-03T00:20:22.361048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[1766,   41, 2428,   99,   26],\n",
      "        [  18,    8,    6,   25,   27],\n",
      "        [1767,  783, 2429,    7, 2087],\n",
      "        [   6,  302, 2430,   27,    6],\n",
      "        [ 580,  784,   10,  359,    2],\n",
      "        [  18,   19,    8,   34,    0],\n",
      "        [1768,  785,   81,  490,    0],\n",
      "        [   6,  249,  332,  201,    0],\n",
      "        [1769,   33,  990,  476,    0],\n",
      "        [  18,   40,   36,    6,    0],\n",
      "        [   6,  302,    6,    2,    0],\n",
      "        [   6,   13,    2,    0,    0],\n",
      "        [   6,    2,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "Input_emotion: tensor([1, 0, 2, 4, 2])\n",
      "lengths: tensor([14, 13, 12, 11,  5])\n",
      "target_variable: tensor([[ 301,   21, 2431,   19,  181],\n",
      "        [ 302,   16,    6,   86, 1296],\n",
      "        [   6,   85,   25, 1838,    6],\n",
      "        [ 204,  196,   81, 1839,    2],\n",
      "        [  16,  786,  133,   34,    0],\n",
      "        [  31,   39,    2,  289,    0],\n",
      "        [ 117,   40,    0,    6,    0],\n",
      "        [   6,    6,    0,    8,    0],\n",
      "        [   2,    2,    0,    7,    0],\n",
      "        [   0,    0,    0,   46,    0],\n",
      "        [   0,    0,    0,  260,    0],\n",
      "        [   0,    0,    0,    8,    0],\n",
      "        [   0,    0,    0,  429,    0],\n",
      "        [   0,    0,    0, 1063,    0],\n",
      "        [   0,    0,    0,    6,    0],\n",
      "        [   0,    0,    0,    2,    0]])\n",
      "target_emotion: tensor([4, 0, 1, 3, 2])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0]], dtype=torch.uint8)\n",
      "max_target_len: 16\n"
     ]
    }
   ],
   "source": [
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(list(range(len(pairs)))) for _ in range(small_batch_size)],pairs,pairs_emotion)\n",
    "input_variable,input_emotion, lengths, target_variable,target_emotion, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print('Input_emotion:',input_emotion)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print('target_emotion:',target_emotion)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.384721Z",
     "start_time": "2019-04-03T00:20:22.372826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden\n",
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECM: Internal memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.394866Z",
     "start_time": "2019-04-03T00:20:22.386874Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ECMWrapper(nn.Module):\n",
    "    '''\n",
    "    Internal memory module\n",
    "    '''\n",
    "    def __init__(self,hidden_size,state_size,emo_size,num_emotion,embedding,emotion_embedding,gru):\n",
    "        '''\n",
    "        hidden_size: hidden input dimension\n",
    "        state_size: state vector size (input a word so hidden size)\n",
    "        emo_size: emotional embedding size (usually similar to hidden_size)\n",
    "        num_emotion: number of emotion categories\n",
    "        '''\n",
    "        super(ECMWrapper,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = state_size\n",
    "        self.emo_size = emo_size\n",
    "        self.num_emotion = num_emotion\n",
    "        # read gate dimensions (word_embedding + hidden_input + context_input)\n",
    "        self.read_g = nn.Linear(self.hidden_size + self.hidden_size + self.hidden_size,self.emo_size)\n",
    "        # write gate\n",
    "        self.write_g = nn.Linear(self.state_size, self.emo_size)\n",
    "        # GRU output input dimensions = state_last + context + emotion emb + internal memory\n",
    "        self.gru = gru\n",
    "        self.emotion_embedding = emotion_embedding\n",
    "        self.embedding = embedding\n",
    "    def forward(self,word_input,emotion_input,last_hidden,context_input):\n",
    "        '''\n",
    "        Last hidden == prev_cell_state\n",
    "        last word embedding = word_input\n",
    "        last hidden input = h\n",
    "        '''\n",
    "        # get embedding of input word and emotion\n",
    "        context_input = context_input.unsqueeze(dim = 0)\n",
    "        last_word_embedding = self.embedding(word_input)\n",
    "        # sum bidirectional hidden input\n",
    "        last_hidden_sum = torch.sum(last_hidden,dim = 0).unsqueeze(dim=0)\n",
    "        read_inputs = torch.cat((last_word_embedding,last_hidden_sum,context_input), dim = -1)\n",
    "        # compute read input\n",
    "        read_inputs = self.read_g(read_inputs)\n",
    "        M_read = torch.sigmoid(read_inputs)\n",
    "        # write to emotion embedding\n",
    "        emotion_input = emotion_input * M_read\n",
    "        # pass everything to GRU\n",
    "        X = torch.cat([last_word_embedding,last_hidden_sum, context_input, emotion_input], dim = -1)\n",
    "        rnn_output, hidden = self.gru(X,last_hidden)\n",
    "        # write input\n",
    "        M_write = torch.sigmoid(self.write_g(rnn_output))\n",
    "        # write to emotion embedding\n",
    "        new_M_emo = emotion_input * M_write\n",
    "        return rnn_output, hidden, new_M_emo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.410809Z",
     "start_time": "2019-04-03T00:20:22.396793Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding,emotion_embedding, hidden_size, output_size,ememory=None, n_layers=1, dropout=0.1,num_emotions = 7):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.num_emotions = num_emotions\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        # define emotion embedding\n",
    "        self.emotion_embedding = emotion_embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        #self.emotion_embedding_dropout = nn.Dropout(dropout)\n",
    "        # dimension\n",
    "        self.gru = nn.GRU(hidden_size + hidden_size + hidden_size + hidden_size , hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        self.internal_memory = ECMWrapper(hidden_size,hidden_size,\n",
    "                                          hidden_size,self.num_emotions,\n",
    "                                          self.embedding,self.emotion_embedding,self.gru)\n",
    "        # read external from outside\n",
    "        self.external_memory = ememory\n",
    "        # emotional output linear layer \n",
    "        self.emotion_word_output_layer = nn.Linear(self.hidden_size,output_size)\n",
    "        # emotional gate/ choice layer\n",
    "        self.alpha_layer = nn.Linear(output_size,1)\n",
    "        \n",
    "    def forward(self, input_step,input_step_emotion, last_hidden\n",
    "                ,input_context, encoder_outputs):\n",
    "        '''\n",
    "        First input_context will be a random vectors\n",
    "        '''\n",
    "        if not torch.is_floating_point(input_step_emotion):\n",
    "            input_step_emotion = self.emotion_embedding(input_step_emotion)\n",
    "        rnn_output, hidden, new_M_emo = self.internal_memory(input_step,input_step_emotion,\n",
    "                                                            last_hidden,input_context)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        if self.external_memory is not None:\n",
    "            # Predict next word using Luong eq. 6\n",
    "            output = self.out(concat_output)\n",
    "            # external memory gate\n",
    "            g = torch.sigmoid(self.alpha_layer(output))\n",
    "            # splice tensor based on ememory\n",
    "            try:\n",
    "                output_e = output[:,-3000:]\n",
    "                output_g = output[:,:-3000]\n",
    "            except Exception as e:\n",
    "                with open('log.txt','a+') as f:\n",
    "                    f.write(e)\n",
    "            # get indices of emotion word and genric word\n",
    "            idx_e = (self.external_memory == 1).nonzero().reshape(-1)\n",
    "            idx_g = (self.external_memory == 0).nonzero().reshape(-1)\n",
    "            # compute softmax output\n",
    "            output_e = F.softmax(output_e,dim=1) * (g)\n",
    "            output_g = F.softmax(output_g,dim=1) * (1 - g)\n",
    "            output = torch.cat((output_e,output_g),dim=1)\n",
    "            #idx = torch.cat((idx_e,idx_g),dim = 0)\n",
    "            #idx_sort,_ = torch.sort(idx,dim = 0,descending = False)\n",
    "            #output = output[:,idx_sort]\n",
    "        else:\n",
    "            # Predict next word using Luong eq. 6\n",
    "            output = self.out(concat_output)\n",
    "            # generic output\n",
    "            output = F.softmax(output, dim=1)\n",
    "        \n",
    "        # Return output and final hidden state\n",
    "        return output, hidden, new_M_emo, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLL Loss + Internal Memory Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.417398Z",
     "start_time": "2019-04-03T00:20:22.413116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maskNLLLoss_IMemory(inp, target, mask,M_emo):\n",
    "    '''\n",
    "    When external memory input will be a tuple with 4 elements\n",
    "    '''\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).sum() + torch.norm(M_emo)\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.432980Z",
     "start_time": "2019-04-03T00:20:22.419994Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_perplexity(loss):\n",
    "    return np.exp(loss)\n",
    "def train(input_variable, lengths, target_variable,target_variable_emotion,\n",
    "          mask, max_target_len, encoder, decoder, embedding,emotion_embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    target_variable_emotion = target_variable_emotion.to(device)\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "    \n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    # Set initial context value,last_rnn_output, internal_memory\n",
    "    context_input = torch.FloatTensor(batch_size,hidden_size)\n",
    "    context_input = context_input.to(device)\n",
    "    # last_rnn_output = torch.FloatTensor(hidden_size)\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    if random.random() < teacher_forcing_ratio:\n",
    "        use_teacher_forcing = True  \n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    \n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden,target_variable_emotion,context_input = decoder(\n",
    "                decoder_input,target_variable_emotion, decoder_hidden,\n",
    "                context_input, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss_IMemory(decoder_output, target_variable[t], mask[t],target_variable_emotion)\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item()) # print average loss\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden,target_variable_emotion,context_input = decoder(\n",
    "                decoder_input,target_variable_emotion, decoder_hidden,\n",
    "                context_input,encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss_IMemory(decoder_output, target_variable[t], mask[t],target_variable_emotion)\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item()) # print average loss\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.448790Z",
     "start_time": "2019-04-03T00:20:22.435338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs,pairs_emotion, \n",
    "               encoder, decoder, encoder_optimizer,\n",
    "               decoder_optimizer, embedding,emotion_embedding, \n",
    "               encoder_n_layers, decoder_n_layers, save_dir, \n",
    "               n_iteration, batch_size, print_every, save_every, \n",
    "               clip,corpus_name,external_memory):\n",
    "    loadFilename=None\n",
    "    # Load batches for each iteration\n",
    "    #training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      #for _ in range(n_iteration)]\n",
    "    print('Loading Training data ...')\n",
    "    length_pairs = len(pairs)\n",
    "    #training_batches = [batch2TrainData(voc, [random.choice(range(length_pairs)) for _ in range(batch_size)],\n",
    "    #                                   pairs,pairs_emotion) for _ in range(n_iteration)]\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        #training_batch = batch2TrainData(voc, [random.choice(range(length_pairs)) for _ in range(batch_size)],\n",
    "        #                               pairs,pairs_emotion)\n",
    "        \n",
    "        with open('wrong_data.pickle','rb') as f:\n",
    "            training_batch = pickle.load(f)\n",
    "        \n",
    "        # Extract fields from batch\n",
    "        input_variable,input_variable_emotion, lengths, target_variable,target_variable_emotion, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss,loss_tensor = train(input_variable, lengths, target_variable,target_variable_emotion,\n",
    "                     mask, max_target_len, encoder,\n",
    "                     decoder, embedding,emotion_embedding,\n",
    "                     encoder_optimizer, decoder_optimizer, \n",
    "                     batch_size, clip)\n",
    "        \n",
    "        #print(loss_tensor)\n",
    "        #if torch.isinf(loss_tensor) or torch.isnan(loss_tensor):\n",
    "        #    with open('wrong_data.pickle','wb') as f:\n",
    "        #        pickle.dump(training_batch,f)\n",
    "        #        raise ValueError('NaN Found')\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0 or iteration == 1:\n",
    "            if iteration == 1:\n",
    "                print_loss_avg = print_loss / 1\n",
    "            else:\n",
    "                print_loss_avg = print_loss / print_every\n",
    "            perplexity = compute_perplexity(print_loss_avg)\n",
    "            output = \"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}; Perplexity: {:.2f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg,perplexity)\n",
    "            print(output)\n",
    "            with open('log.txt','a+') as f:\n",
    "                f.write(output + '\\n')\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict(),\n",
    "                'external_memory':external_memory\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropatation\n",
    "loss.backward()\n",
    "\n",
    "# Clip gradients: gradients are modified in place\n",
    "_ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "_ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "# Adjust model weights\n",
    "encoder_optimizer.step()\n",
    "decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5592.8350, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_param(model):\n",
    "    for name,param in model.named_parameters():\n",
    "        print(param)\n",
    "        print(name,param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.459565Z",
     "start_time": "2019-04-03T00:20:22.451396Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder,num_word = None):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq,target_emotions,input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Set initial context value,last_rnn_output, internal_memory\n",
    "        context_input = torch.FloatTensor(1,hidden_size)\n",
    "        context_input = context_input.to(device)\n",
    "        # last_rnn_output = torch.FloatTensor(hidden_size)\n",
    "        internal_memory = torch.FloatTensor(batch_size,hidden_size)\n",
    "        internal_memory = internal_memory.to(device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden,target_emotions,context_input = decoder(\n",
    "                decoder_input,target_emotions, decoder_hidden,\n",
    "                context_input, encoder_outputs\n",
    "            )\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.474049Z",
     "start_time": "2019-04-03T00:20:22.461944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BeamSearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder,num_word):\n",
    "        super(BeamSearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.num_word = num_word\n",
    "\n",
    "    def forward(self, input_seq,target_emotions,input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_words_order = torch.zeros((1,self.num_word),device=device,dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        all_scores_array = torch.zeros((1,self.num_word),device=device,dtype=torch.float)\n",
    "        # Set initial context value,last_rnn_output, internal_memory\n",
    "        context_input = torch.ones(1,hidden_size,dtype=torch.float)\n",
    "        context_input = context_input.to(device)\n",
    "        # last_rnn_output = torch.FloatTensor(hidden_size)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden,target_emotions,context_input = decoder(\n",
    "                decoder_input,target_emotions, decoder_hidden,\n",
    "                context_input, encoder_outputs\n",
    "            )\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            decoder_input_order = torch.argsort(decoder_output,dim=1,descending=True)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            all_scores_array = torch.cat((all_scores_array,decoder_output),dim = 0)\n",
    "            all_words_order = torch.cat((all_words_order,decoder_input_order), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        sequences = self.beam_search(all_scores_array,3)\n",
    "        return sequences\n",
    "    def beam_search(self,array,k):\n",
    "        array = array.tolist()\n",
    "        sequences = [[list(), 1.0]]\n",
    "        # walk over each step in sequence\n",
    "        for row in array:\n",
    "            all_candidates = list()\n",
    "            # expand each current candidate\n",
    "            for i in range(len(sequences)):\n",
    "                seq, score = sequences[i]\n",
    "                for j in range(len(row)):\n",
    "                    candidate = [seq + [j], score * -np.log(row[j] + 1e-8)]\n",
    "                    all_candidates.append(candidate)\n",
    "            # order all candidates by score\n",
    "            ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "            # select k best\n",
    "            sequences = ordered[:k]\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:22.688663Z",
     "start_time": "2019-04-03T00:20:22.476414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion word counts: 2135\n",
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'emotion_model'\n",
    "corpus_name = 'dailydialogue'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "# number of emotion\n",
    "num_emotions = 5\n",
    "# load external memory based vocab.\n",
    "emotion_words = get_ememory('ememory.txt',voc)\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None #'data/save/emotion_model/dailydialogue/2-2_500/10000_checkpoint.tar'\n",
    "checkpoint_iter = 120\n",
    "training = True\n",
    "if loadFilename:\n",
    "    training = False\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "    emotion_words = checkpoint['external_memory']\n",
    "    \n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "emotion_embedding = nn.Embedding(num_emotions, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding,emotion_embedding, hidden_size, \n",
    "                              voc.num_words, emotion_words,decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "    \n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:45.601591Z",
     "start_time": "2019-04-03T00:20:22.690677Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Loading Training data ...\n",
      "Initializing ...\n",
      "Training...\n",
      "tensor([[ 0.0695,  0.0698,  0.0784,  ..., -0.0654,  0.0987, -0.1133],\n",
      "        [ 0.0139,  0.0256,  0.2158,  ...,  0.0453,  0.0188,  0.0833],\n",
      "        [ 0.0574,  0.0664, -0.0676,  ..., -0.0866, -0.0685,  0.0191],\n",
      "        ...,\n",
      "        [-0.0570,  0.0345, -0.1007,  ..., -0.0422,  0.0491, -0.0221],\n",
      "        [ 0.0813, -0.0131, -0.0727,  ..., -0.0489, -0.0259, -0.0228],\n",
      "        [ 0.0690,  0.0063, -0.0365,  ..., -0.1268,  0.1175,  0.0441]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0806,  0.0528,  0.0994,  ..., -0.0494,  0.0575, -0.0797],\n",
      "        [ 0.0413, -0.0247,  0.1680,  ..., -0.0240,  0.0132,  0.0846],\n",
      "        [ 0.0457,  0.0703, -0.0532,  ..., -0.1328,  0.0117,  0.0661],\n",
      "        ...,\n",
      "        [-0.0644,  0.0437, -0.0120,  ..., -0.0727,  0.0391, -0.0080],\n",
      "        [ 0.0557,  0.0473, -0.0499,  ..., -0.1223,  0.0103, -0.0059],\n",
      "        [ 0.0689, -0.0019, -0.0456,  ..., -0.0578,  0.0619,  0.1334]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0577,  0.0385,  0.0901,  ..., -0.0920,  0.1213, -0.0499],\n",
      "        [ 0.0853, -0.0791,  0.1261,  ..., -0.0471, -0.0258,  0.0862],\n",
      "        [ 0.0915,  0.0392, -0.0236,  ..., -0.1879,  0.0489,  0.1248],\n",
      "        ...,\n",
      "        [-0.0364,  0.0071, -0.0117,  ..., -0.1054,  0.0498,  0.0341],\n",
      "        [ 0.0353,  0.0956, -0.0091,  ..., -0.0782, -0.0236,  0.0223],\n",
      "        [ 0.0786,  0.0287,  0.0042,  ..., -0.0914,  0.0661,  0.1272]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0151,  0.0127,  0.1150,  ..., -0.1063,  0.1198, -0.0634],\n",
      "        [ 0.1252, -0.1032,  0.1110,  ..., -0.0474, -0.0191,  0.0871],\n",
      "        [ 0.1022,  0.0323, -0.0072,  ..., -0.1814,  0.0769,  0.1607],\n",
      "        ...,\n",
      "        [ 0.0063, -0.0114,  0.0201,  ..., -0.1254,  0.0666,  0.0930],\n",
      "        [ 0.0449,  0.0735,  0.0036,  ..., -0.0783, -0.0335,  0.0499],\n",
      "        [ 0.0963,  0.0993, -0.0217,  ..., -0.1082,  0.0708,  0.1102]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0077, -0.0339,  0.1554,  ..., -0.0999,  0.1376, -0.0888],\n",
      "        [ 0.1335, -0.1203,  0.1126,  ..., -0.0956,  0.0062,  0.0761],\n",
      "        [ 0.1355,  0.0300, -0.0438,  ..., -0.1659,  0.0586,  0.1874],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0243,  0.0300,  ..., -0.1765,  0.0201,  0.0793],\n",
      "        [ 0.0346,  0.0964, -0.0186,  ..., -0.0805, -0.0628,  0.0698],\n",
      "        [ 0.0567,  0.0950, -0.0357,  ..., -0.1057,  0.0212,  0.0880]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0353, -0.0625,  0.1582,  ..., -0.0871,  0.1618, -0.0797],\n",
      "        [ 0.1477, -0.0839,  0.0907,  ..., -0.0632,  0.0169,  0.0973],\n",
      "        [ 0.1200,  0.0477, -0.0129,  ..., -0.1656,  0.0579,  0.2167],\n",
      "        ...,\n",
      "        [ 0.0625,  0.0359,  0.0130,  ..., -0.2096,  0.0402,  0.0926],\n",
      "        [ 0.0215,  0.0543, -0.0272,  ..., -0.0875, -0.0892,  0.0431],\n",
      "        [ 0.0430,  0.0685, -0.0431,  ..., -0.0676, -0.0422,  0.0745]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0296, -0.0487,  0.1247,  ..., -0.1180,  0.2500, -0.1170],\n",
      "        [ 0.1493, -0.1466,  0.0490,  ..., -0.1307, -0.0328,  0.0148],\n",
      "        [ 0.1407,  0.0317,  0.0064,  ..., -0.1863,  0.0587,  0.2142],\n",
      "        ...,\n",
      "        [ 0.1122,  0.0650,  0.0150,  ..., -0.1838,  0.0126,  0.0624],\n",
      "        [-0.0135,  0.0612, -0.0533,  ..., -0.0809, -0.1231,  0.0479],\n",
      "        [ 0.0315,  0.0354, -0.0301,  ..., -0.0457, -0.0270,  0.0948]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-5.2541e-02, -8.7674e-03,  8.7425e-02,  ..., -1.4868e-01,\n",
      "          1.5933e-01, -1.1151e-01],\n",
      "        [ 1.7270e-01, -9.2246e-02,  9.2055e-02,  ..., -1.0049e-01,\n",
      "          3.4408e-02,  1.3828e-02],\n",
      "        [ 1.2515e-01, -9.0276e-03, -3.5948e-02,  ..., -1.9502e-01,\n",
      "          5.1329e-03,  1.5036e-01],\n",
      "        ...,\n",
      "        [ 1.0731e-01,  6.4783e-02,  2.2399e-02,  ..., -1.7851e-01,\n",
      "          3.3778e-02,  4.6006e-02],\n",
      "        [-3.6019e-02,  1.4228e-02, -2.0564e-02,  ..., -9.0205e-02,\n",
      "         -1.0512e-01,  3.8639e-03],\n",
      "        [ 6.4408e-03,  3.6621e-02,  1.5970e-02,  ..., -6.8629e-05,\n",
      "         -1.3279e-02,  1.1078e-01]], grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0154, -0.0070,  0.0438,  ..., -0.1146,  0.1761, -0.0820],\n",
      "        [ 0.1097, -0.1154,  0.0972,  ..., -0.0991,  0.0747,  0.0033],\n",
      "        [ 0.0920,  0.0165, -0.0306,  ..., -0.1977, -0.0214,  0.0858],\n",
      "        ...,\n",
      "        [ 0.0704,  0.0155, -0.0070,  ..., -0.1383,  0.0175, -0.0113],\n",
      "        [-0.0144,  0.0037,  0.0252,  ..., -0.1213, -0.0565,  0.0131],\n",
      "        [ 0.0023,  0.0280,  0.0163,  ..., -0.0013,  0.0245,  0.1234]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 8.3962e-03, -1.4252e-04,  7.9193e-02,  ..., -1.2759e-01,\n",
      "          2.1839e-01, -7.8355e-02],\n",
      "        [ 3.6366e-02, -1.3538e-01,  8.8824e-02,  ..., -7.7964e-02,\n",
      "          1.1175e-01,  4.1561e-02],\n",
      "        [ 3.7608e-02,  5.7574e-02, -4.8427e-02,  ..., -1.7853e-01,\n",
      "         -4.9555e-02,  2.9390e-02],\n",
      "        ...,\n",
      "        [ 6.2060e-02, -4.0110e-02, -8.6136e-03,  ..., -1.2129e-01,\n",
      "          2.3147e-02,  2.0814e-02],\n",
      "        [ 6.4013e-03,  6.4847e-02,  8.6209e-02,  ..., -1.2783e-01,\n",
      "         -2.0540e-02, -9.6930e-03],\n",
      "        [-5.3433e-02,  6.1227e-04,  1.0534e-02,  ..., -4.0025e-04,\n",
      "          3.0017e-02,  1.5058e-01]], grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0652, -0.0311,  0.0775,  ..., -0.1209,  0.2099, -0.0965],\n",
      "        [ 0.0308, -0.1505,  0.0779,  ..., -0.0738,  0.1097, -0.0019],\n",
      "        [ 0.0027,  0.0541, -0.0182,  ..., -0.1660, -0.0878,  0.0776],\n",
      "        ...,\n",
      "        [ 0.0252, -0.0648, -0.0095,  ..., -0.1315,  0.0049, -0.0221],\n",
      "        [ 0.0358,  0.0975,  0.1066,  ..., -0.1520,  0.0033, -0.0387],\n",
      "        [-0.0222, -0.0218, -0.0169,  ..., -0.0223,  0.0381,  0.1255]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0955, -0.0350,  0.0851,  ..., -0.1405,  0.1272, -0.1233],\n",
      "        [ 0.0177, -0.1428,  0.0931,  ..., -0.0464,  0.0872, -0.0100],\n",
      "        [-0.0031,  0.0756,  0.0179,  ..., -0.1831, -0.1019,  0.0797],\n",
      "        ...,\n",
      "        [-0.0179,  0.0293,  0.0312,  ..., -0.1029,  0.0076, -0.0433],\n",
      "        [ 0.0412,  0.0945,  0.1060,  ..., -0.1133,  0.0076, -0.0306],\n",
      "        [-0.0116,  0.0031, -0.0316,  ..., -0.0463,  0.0754,  0.1206]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0516, -0.0188,  0.0836,  ..., -0.1420,  0.0671, -0.1152],\n",
      "        [ 0.0395, -0.1209,  0.0218,  ..., -0.0226, -0.0226,  0.0303],\n",
      "        [ 0.0173,  0.1812,  0.0298,  ..., -0.1911,  0.0007,  0.0913],\n",
      "        ...,\n",
      "        [ 0.0417,  0.0174,  0.0575,  ..., -0.1230, -0.0226, -0.0439],\n",
      "        [ 0.0354,  0.0490,  0.0580,  ..., -0.0872,  0.0080, -0.0183],\n",
      "        [-0.0066,  0.0223, -0.0134,  ..., -0.0823,  0.0426,  0.0942]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0026, -0.0268,  0.0869,  ..., -0.1427,  0.0610, -0.1034],\n",
      "        [ 0.0852, -0.1411,  0.0042,  ..., -0.0045, -0.0106, -0.0170],\n",
      "        [ 0.0321,  0.2254,  0.0044,  ..., -0.1702,  0.0841,  0.0610],\n",
      "        ...,\n",
      "        [ 0.0917, -0.0354,  0.1110,  ..., -0.1519, -0.0642, -0.0121],\n",
      "        [ 0.0097,  0.0044,  0.0702,  ..., -0.0799, -0.0308, -0.0389],\n",
      "        [ 0.0073,  0.0043, -0.0602,  ..., -0.0393, -0.0275,  0.0705]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0151, -0.0644,  0.1522,  ..., -0.0923,  0.0914, -0.0853],\n",
      "        [ 0.1019, -0.1465, -0.0017,  ...,  0.0257,  0.0347, -0.0280],\n",
      "        [ 0.0081,  0.2478, -0.0048,  ..., -0.2035,  0.0798,  0.1085],\n",
      "        ...,\n",
      "        [ 0.1524, -0.0652,  0.1533,  ..., -0.1565, -0.0824, -0.0200],\n",
      "        [ 0.0185, -0.0210,  0.0276,  ..., -0.0531, -0.0430, -0.0537],\n",
      "        [-0.0035,  0.0625, -0.0387,  ..., -0.0048, -0.0879,  0.0524]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0063,  0.0252,  0.1662,  ..., -0.0279,  0.0763, -0.0531],\n",
      "        [ 0.1111, -0.1365,  0.0079,  ...,  0.0428,  0.0008, -0.0521],\n",
      "        [-0.0882,  0.1840,  0.0635,  ..., -0.1798,  0.1224,  0.0975],\n",
      "        ...,\n",
      "        [ 0.1037, -0.0395,  0.1145,  ..., -0.1477, -0.0203, -0.0300],\n",
      "        [ 0.0113, -0.0488,  0.0170,  ..., -0.0596, -0.0427, -0.0315],\n",
      "        [ 0.0361,  0.0209, -0.0372,  ...,  0.0460, -0.0688,  0.0303]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0113,  0.0244,  0.1602,  ..., -0.0120,  0.0797, -0.0127],\n",
      "        [ 0.1421, -0.0730, -0.0249,  ...,  0.0721,  0.0335, -0.0670],\n",
      "        [-0.1010,  0.1783,  0.0093,  ..., -0.1721,  0.0988,  0.0379],\n",
      "        ...,\n",
      "        [ 0.0664,  0.0037,  0.0608,  ..., -0.1308, -0.0155, -0.0068],\n",
      "        [ 0.0463, -0.0422,  0.0454,  ..., -0.0848,  0.0126, -0.0339],\n",
      "        [ 0.0207, -0.0130,  0.0116,  ..., -0.0091, -0.0712,  0.0321]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0530, -0.0265,  0.0910,  ..., -0.0566,  0.1156, -0.0075],\n",
      "        [ 0.1129, -0.0551, -0.0058,  ...,  0.0251,  0.0057, -0.0131],\n",
      "        [-0.0760,  0.0753,  0.0015,  ..., -0.1341,  0.0628,  0.0462],\n",
      "        ...,\n",
      "        [ 0.0305, -0.0359,  0.0285,  ..., -0.1146,  0.0044, -0.0019],\n",
      "        [ 0.0439, -0.0382,  0.0893,  ..., -0.0371,  0.0572, -0.0456],\n",
      "        [ 0.0365,  0.0092,  0.0008,  ..., -0.0376, -0.0321,  0.0040]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0406, -0.0055,  0.0885,  ..., -0.0086,  0.1146, -0.0062],\n",
      "        [ 0.0712, -0.0306,  0.0456,  ..., -0.0204, -0.0430,  0.0509],\n",
      "        [-0.0759,  0.1111, -0.0259,  ..., -0.0983,  0.0028,  0.0841],\n",
      "        ...,\n",
      "        [ 0.0076, -0.0587,  0.0356,  ..., -0.0975,  0.0277,  0.0109],\n",
      "        [-0.0119, -0.0251,  0.1345,  ..., -0.0730,  0.1218, -0.0361],\n",
      "        [ 0.0351, -0.0075, -0.0348,  ..., -0.0340, -0.0176, -0.0171]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0934,  0.0054,  0.0535,  ...,  0.0390,  0.1007, -0.0449],\n",
      "        [ 0.1348,  0.0800,  0.0852,  ...,  0.0188, -0.0131, -0.0098],\n",
      "        [-0.0716,  0.1054, -0.0185,  ..., -0.1054, -0.0245,  0.1091],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0304,  0.0586,  ..., -0.0739, -0.0102,  0.0219],\n",
      "        [ 0.0554, -0.0272,  0.0743,  ..., -0.0875,  0.1226, -0.0547],\n",
      "        [ 0.0188, -0.0319, -0.0244,  ..., -0.0553, -0.0300, -0.0047]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.1263,  0.0676,  0.0256,  ...,  0.0253,  0.0883, -0.0748],\n",
      "        [ 0.1920,  0.1558,  0.1122,  ...,  0.0778,  0.0037, -0.0613],\n",
      "        [-0.0560,  0.1725, -0.0079,  ..., -0.0730,  0.0391,  0.1010],\n",
      "        ...,\n",
      "        [ 0.0051,  0.0115,  0.0556,  ..., -0.0614, -0.0268,  0.0075],\n",
      "        [ 0.0624, -0.0261,  0.0244,  ..., -0.0591,  0.0981, -0.0505],\n",
      "        [ 0.0013, -0.0703, -0.0399,  ..., -0.0530, -0.0142,  0.0113]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.1571,  0.1162,  0.0141,  ...,  0.0167,  0.1235, -0.1041],\n",
      "        [ 0.1429,  0.1385,  0.1157,  ...,  0.0879,  0.0258, -0.0945],\n",
      "        [-0.0593,  0.1811, -0.0060,  ..., -0.1017,  0.0410,  0.1255],\n",
      "        ...,\n",
      "        [ 0.0359,  0.0156,  0.0802,  ..., -0.0318, -0.0072, -0.0275],\n",
      "        [ 0.0687, -0.0229,  0.0039,  ..., -0.0794,  0.1052, -0.1038],\n",
      "        [ 0.0372, -0.0353, -0.0033,  ..., -0.0340,  0.0413, -0.0218]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0875e-01,  8.8982e-02,  2.2962e-02,  ...,  1.7319e-02,\n",
      "          9.9479e-02, -1.2593e-01],\n",
      "        [ 1.1937e-01,  1.1270e-01,  1.2186e-01,  ...,  1.0355e-01,\n",
      "          1.5454e-02, -1.1655e-01],\n",
      "        [-5.3395e-02,  1.9153e-01,  2.7735e-02,  ..., -1.3970e-01,\n",
      "          2.3585e-02,  7.8012e-02],\n",
      "        ...,\n",
      "        [ 1.5545e-02,  3.4528e-02,  6.4092e-02,  ..., -1.5501e-02,\n",
      "         -3.7765e-02, -6.4863e-03],\n",
      "        [ 8.1738e-02, -4.4096e-02, -3.9018e-02,  ..., -3.8180e-02,\n",
      "          9.4562e-02, -9.1781e-02],\n",
      "        [ 5.4696e-02, -1.4270e-02, -1.8394e-05,  ..., -2.3227e-02,\n",
      "          4.3933e-02, -6.6348e-02]], grad_fn=<TanhBackward>)\n",
      "Iteration: 1; Percent complete: 0.0%; Average loss: 8.8102; Perplexity: 6702.50\n",
      "tensor([[ 0.2959, -0.0036,  0.0995,  ..., -0.1130, -0.1644, -0.3581],\n",
      "        [ 0.5063, -0.3119,  0.0426,  ...,  0.4898, -0.0873, -0.3333],\n",
      "        [ 0.2917, -0.1413, -0.0595,  ...,  0.3201, -0.2111, -0.3127],\n",
      "        ...,\n",
      "        [ 0.1011, -0.1278, -0.0974,  ...,  0.2480,  0.0874, -0.2083],\n",
      "        [ 0.2319, -0.2365, -0.0803,  ...,  0.3509, -0.0075, -0.1314],\n",
      "        [ 0.2752, -0.2230, -0.1650,  ...,  0.2666,  0.1548, -0.1828]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.3699, -0.0028,  0.1679,  ...,  0.1605, -0.0978, -0.3365],\n",
      "        [ 0.5492, -0.3588, -0.0387,  ...,  0.5633, -0.1359, -0.3487],\n",
      "        [ 0.3177, -0.2028, -0.0831,  ...,  0.4764, -0.1621, -0.2762],\n",
      "        ...,\n",
      "        [ 0.2092, -0.1308, -0.0309,  ...,  0.3739,  0.0472, -0.2426],\n",
      "        [ 0.2209, -0.2436, -0.0474,  ...,  0.4375,  0.0212, -0.1468],\n",
      "        [ 0.3070, -0.1776, -0.0696,  ...,  0.4064,  0.1024, -0.1289]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.4147, -0.0945,  0.1652,  ...,  0.2916, -0.0285, -0.3290],\n",
      "        [ 0.5144, -0.4095, -0.0200,  ...,  0.6041, -0.1376, -0.2884],\n",
      "        [ 0.3890, -0.3040, -0.0961,  ...,  0.5900, -0.1420, -0.2525],\n",
      "        ...,\n",
      "        [ 0.1975, -0.0452,  0.0792,  ...,  0.4410, -0.0073, -0.1754],\n",
      "        [ 0.2899, -0.3020,  0.0246,  ...,  0.4885, -0.0277, -0.1313],\n",
      "        [ 0.5137, -0.2890, -0.0537,  ...,  0.5476,  0.0205, -0.1857]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.4494, -0.1691,  0.1582,  ...,  0.4423, -0.0290, -0.2900],\n",
      "        [ 0.5020, -0.4277,  0.0135,  ...,  0.6389, -0.1212, -0.2639],\n",
      "        [ 0.4554, -0.3541, -0.0668,  ...,  0.6411, -0.1239, -0.1899],\n",
      "        ...,\n",
      "        [ 0.2040, -0.0848,  0.1727,  ...,  0.4518, -0.0260, -0.1244],\n",
      "        [ 0.3236, -0.3462,  0.0866,  ...,  0.4959, -0.0331, -0.1027],\n",
      "        [ 0.5384, -0.3491, -0.0260,  ...,  0.5841, -0.0276, -0.2012]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.4959, -0.2716,  0.1039,  ...,  0.5663, -0.0228, -0.2802],\n",
      "        [ 0.4974, -0.4533,  0.0059,  ...,  0.6411, -0.1354, -0.2422],\n",
      "        [ 0.4724, -0.3538, -0.1068,  ...,  0.6559, -0.1007, -0.1592],\n",
      "        ...,\n",
      "        [ 0.2014, -0.1398,  0.2208,  ...,  0.4670,  0.0039, -0.0167],\n",
      "        [ 0.3085, -0.3918,  0.1481,  ...,  0.5391, -0.0222, -0.0444],\n",
      "        [ 0.4981, -0.3834,  0.0007,  ...,  0.5726,  0.0021, -0.1678]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5390, -0.2908,  0.0733,  ...,  0.6282, -0.0423, -0.3021],\n",
      "        [ 0.5043, -0.4362,  0.0346,  ...,  0.6433, -0.1179, -0.2083],\n",
      "        [ 0.4865, -0.3645, -0.0644,  ...,  0.6837, -0.1305, -0.1211],\n",
      "        ...,\n",
      "        [ 0.1366, -0.1837,  0.2344,  ...,  0.4685, -0.0225,  0.0014],\n",
      "        [ 0.3371, -0.3885,  0.1654,  ...,  0.5530, -0.0477, -0.0266],\n",
      "        [ 0.4904, -0.3593, -0.0043,  ...,  0.5917, -0.0136, -0.1423]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5424, -0.3339,  0.0899,  ...,  0.6574, -0.0510, -0.2714],\n",
      "        [ 0.5035, -0.4652,  0.0093,  ...,  0.6523, -0.1150, -0.1796],\n",
      "        [ 0.4758, -0.3772, -0.0750,  ...,  0.6769, -0.1405, -0.0514],\n",
      "        ...,\n",
      "        [ 0.1006, -0.2105,  0.2492,  ...,  0.4521,  0.0333,  0.0153],\n",
      "        [ 0.2845, -0.3687,  0.1386,  ...,  0.5480, -0.0514, -0.0223],\n",
      "        [ 0.4780, -0.3910,  0.0533,  ...,  0.6078,  0.0048, -0.1378]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5623, -0.3738,  0.1404,  ...,  0.6674, -0.0351, -0.2715],\n",
      "        [ 0.5327, -0.4696,  0.0397,  ...,  0.6943, -0.0517, -0.2032],\n",
      "        [ 0.4483, -0.3680, -0.0104,  ...,  0.6805, -0.1484, -0.0454],\n",
      "        ...,\n",
      "        [ 0.0591, -0.1998,  0.2607,  ...,  0.4504,  0.0456,  0.0205],\n",
      "        [ 0.2996, -0.3458,  0.2077,  ...,  0.4955, -0.0445, -0.0551],\n",
      "        [ 0.4775, -0.4100,  0.0293,  ...,  0.5969,  0.0087, -0.1256]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5575, -0.3816,  0.0968,  ...,  0.6765, -0.0846, -0.2448],\n",
      "        [ 0.5431, -0.4785,  0.0872,  ...,  0.7004, -0.0884, -0.1983],\n",
      "        [ 0.4456, -0.3915, -0.0317,  ...,  0.6746, -0.0809, -0.0660],\n",
      "        ...,\n",
      "        [-0.0229, -0.2190,  0.1987,  ...,  0.4241,  0.0562,  0.0345],\n",
      "        [ 0.3090, -0.3654,  0.2097,  ...,  0.5144, -0.0217, -0.0385],\n",
      "        [ 0.4633, -0.4086,  0.0318,  ...,  0.5767, -0.0020, -0.1390]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5704, -0.4194,  0.1069,  ...,  0.6867, -0.1004, -0.2501],\n",
      "        [ 0.5436, -0.4618,  0.1219,  ...,  0.6958, -0.1061, -0.2081],\n",
      "        [ 0.4404, -0.3470,  0.0546,  ...,  0.6301, -0.0669, -0.0923],\n",
      "        ...,\n",
      "        [ 0.0025, -0.2573,  0.1895,  ...,  0.4209,  0.0696,  0.0112],\n",
      "        [ 0.2762, -0.3846,  0.2263,  ...,  0.5146, -0.0548, -0.0432],\n",
      "        [ 0.4525, -0.3856,  0.0127,  ...,  0.5577, -0.0155, -0.1180]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 5.7520e-01, -4.2081e-01,  1.4711e-01,  ...,  6.9551e-01,\n",
      "         -8.4262e-02, -2.5104e-01],\n",
      "        [ 5.2103e-01, -4.6240e-01,  9.8114e-02,  ...,  6.9223e-01,\n",
      "         -1.2660e-01, -1.9023e-01],\n",
      "        [ 4.5867e-01, -3.6276e-01, -3.9617e-04,  ...,  6.6833e-01,\n",
      "         -9.4898e-02, -7.3922e-02],\n",
      "        ...,\n",
      "        [-1.8939e-02, -2.5245e-01,  2.0583e-01,  ...,  4.3627e-01,\n",
      "          4.2203e-02,  3.6151e-02],\n",
      "        [ 3.0433e-01, -3.7974e-01,  2.5449e-01,  ...,  5.0446e-01,\n",
      "         -4.2851e-02, -7.3608e-02],\n",
      "        [ 4.1725e-01, -4.1296e-01, -1.4102e-03,  ...,  5.6802e-01,\n",
      "         -3.1536e-02, -1.5102e-01]], grad_fn=<TanhBackward>)\n",
      "tensor([[ 5.5245e-01, -4.7272e-01,  9.2542e-02,  ...,  6.8218e-01,\n",
      "         -1.2213e-01, -2.4989e-01],\n",
      "        [ 4.9261e-01, -4.2012e-01,  1.0374e-01,  ...,  6.7634e-01,\n",
      "         -1.4397e-01, -2.0506e-01],\n",
      "        [ 4.6962e-01, -4.0762e-01,  3.6310e-02,  ...,  6.6978e-01,\n",
      "         -6.4602e-02, -8.5293e-02],\n",
      "        ...,\n",
      "        [ 3.0947e-04, -2.9846e-01,  1.8955e-01,  ...,  4.5907e-01,\n",
      "          4.2875e-02,  6.3257e-02],\n",
      "        [ 3.0240e-01, -3.7218e-01,  2.6154e-01,  ...,  5.3010e-01,\n",
      "         -2.6441e-02, -6.4393e-02],\n",
      "        [ 4.3574e-01, -4.6077e-01,  6.7343e-02,  ...,  5.5029e-01,\n",
      "         -1.7881e-02, -1.8921e-01]], grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5654, -0.4625,  0.1500,  ...,  0.6659, -0.1398, -0.2559],\n",
      "        [ 0.5279, -0.4455,  0.1100,  ...,  0.6931, -0.1266, -0.2509],\n",
      "        [ 0.4976, -0.4332, -0.0120,  ...,  0.6830, -0.0824, -0.0704],\n",
      "        ...,\n",
      "        [ 0.0155, -0.2734,  0.1523,  ...,  0.4568,  0.0364,  0.0715],\n",
      "        [ 0.3104, -0.3927,  0.2495,  ...,  0.5222, -0.0034, -0.0999],\n",
      "        [ 0.4448, -0.4525,  0.0693,  ...,  0.5804, -0.0272, -0.1703]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5573, -0.4247,  0.1051,  ...,  0.6332, -0.2196, -0.2284],\n",
      "        [ 0.5362, -0.4584,  0.1290,  ...,  0.6892, -0.0880, -0.2330],\n",
      "        [ 0.5022, -0.4323, -0.0060,  ...,  0.6635, -0.0500, -0.0646],\n",
      "        ...,\n",
      "        [ 0.0120, -0.2812,  0.1522,  ...,  0.4732,  0.0722,  0.0301],\n",
      "        [ 0.3230, -0.3779,  0.2485,  ...,  0.5201, -0.0045, -0.1322],\n",
      "        [ 0.4374, -0.4760,  0.0837,  ...,  0.5826, -0.0133, -0.1752]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5624, -0.4501,  0.1052,  ...,  0.6371, -0.1585, -0.2545],\n",
      "        [ 0.5272, -0.4832,  0.1189,  ...,  0.7008, -0.0827, -0.2397],\n",
      "        [ 0.4634, -0.3874,  0.0504,  ...,  0.6242, -0.0577, -0.0823],\n",
      "        ...,\n",
      "        [-0.0097, -0.2672,  0.1788,  ...,  0.4343,  0.0347, -0.0248],\n",
      "        [ 0.3310, -0.3618,  0.2390,  ...,  0.4728, -0.0290, -0.1452],\n",
      "        [ 0.4418, -0.4625,  0.0856,  ...,  0.5969,  0.0313, -0.1459]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5686, -0.4619,  0.0955,  ...,  0.6454, -0.1177, -0.2730],\n",
      "        [ 0.5346, -0.4885,  0.1328,  ...,  0.7086, -0.0636, -0.2227],\n",
      "        [ 0.4578, -0.3997,  0.0330,  ...,  0.6659, -0.0493, -0.0605],\n",
      "        ...,\n",
      "        [ 0.0059, -0.2909,  0.1979,  ...,  0.4080,  0.0202,  0.0225],\n",
      "        [ 0.3247, -0.3925,  0.2277,  ...,  0.4868, -0.0411, -0.1273],\n",
      "        [ 0.4452, -0.4680,  0.1103,  ...,  0.5915,  0.0370, -0.1323]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5205, -0.4390,  0.0990,  ...,  0.6565, -0.0832, -0.2417],\n",
      "        [ 0.5287, -0.4874,  0.1029,  ...,  0.6766, -0.0747, -0.2077],\n",
      "        [ 0.4884, -0.4275,  0.0105,  ...,  0.6915, -0.0774, -0.0343],\n",
      "        ...,\n",
      "        [ 0.0364, -0.2744,  0.1653,  ...,  0.4349,  0.0226,  0.0103],\n",
      "        [ 0.2649, -0.3904,  0.2502,  ...,  0.5010, -0.0100, -0.0678],\n",
      "        [ 0.4544, -0.4572,  0.0834,  ...,  0.5732,  0.0636, -0.1504]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5484, -0.4315,  0.1082,  ...,  0.6704, -0.0692, -0.2330],\n",
      "        [ 0.5069, -0.4738,  0.1099,  ...,  0.6854, -0.0663, -0.1886],\n",
      "        [ 0.5022, -0.4240,  0.0518,  ...,  0.6862, -0.0780, -0.1038],\n",
      "        ...,\n",
      "        [ 0.0550, -0.2810,  0.1849,  ...,  0.4429,  0.0014, -0.0225],\n",
      "        [ 0.2885, -0.4135,  0.2195,  ...,  0.5193,  0.0068, -0.0912],\n",
      "        [ 0.4422, -0.4501,  0.0364,  ...,  0.5565,  0.0521, -0.1363]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5570, -0.4353,  0.0997,  ...,  0.6820, -0.0702, -0.1965],\n",
      "        [ 0.5224, -0.5022,  0.1620,  ...,  0.6890, -0.0646, -0.2266],\n",
      "        [ 0.4968, -0.4227,  0.0612,  ...,  0.6817, -0.0933, -0.1051],\n",
      "        ...,\n",
      "        [ 0.0663, -0.2430,  0.1993,  ...,  0.4069,  0.0669, -0.0357],\n",
      "        [ 0.3110, -0.3900,  0.2586,  ...,  0.5123,  0.0370, -0.1169],\n",
      "        [ 0.4253, -0.4582,  0.0719,  ...,  0.5384,  0.0724, -0.1501]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5535, -0.4527,  0.0705,  ...,  0.6776, -0.0758, -0.2471],\n",
      "        [ 0.5216, -0.5138,  0.1502,  ...,  0.7095, -0.0506, -0.2408],\n",
      "        [ 0.4639, -0.4085,  0.0458,  ...,  0.6470, -0.0990, -0.1129],\n",
      "        ...,\n",
      "        [ 0.0575, -0.2595,  0.1633,  ...,  0.3689,  0.0659, -0.0258],\n",
      "        [ 0.3205, -0.4391,  0.2208,  ...,  0.5111,  0.0010, -0.0830],\n",
      "        [ 0.4080, -0.4420,  0.0356,  ...,  0.5396,  0.0756, -0.1161]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5618, -0.4634,  0.0539,  ...,  0.6608, -0.0619, -0.2387],\n",
      "        [ 0.5340, -0.4795,  0.1375,  ...,  0.6863, -0.0561, -0.2210],\n",
      "        [ 0.4504, -0.3836,  0.0613,  ...,  0.6738, -0.1239, -0.0962],\n",
      "        ...,\n",
      "        [ 0.0626, -0.2919,  0.1685,  ...,  0.3895,  0.0263, -0.0288],\n",
      "        [ 0.3318, -0.3704,  0.1835,  ...,  0.4825,  0.0134, -0.0887],\n",
      "        [ 0.4347, -0.4302,  0.0750,  ...,  0.5735,  0.0807, -0.1426]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5609, -0.4436,  0.0623,  ...,  0.6558, -0.0815, -0.2662],\n",
      "        [ 0.5333, -0.4798,  0.1417,  ...,  0.6628, -0.0512, -0.2372],\n",
      "        [ 0.4927, -0.4056,  0.0323,  ...,  0.6591, -0.1222, -0.0990],\n",
      "        ...,\n",
      "        [ 0.0637, -0.2913,  0.2015,  ...,  0.3972,  0.0687,  0.0092],\n",
      "        [ 0.2977, -0.3556,  0.1762,  ...,  0.4793, -0.0399, -0.0692],\n",
      "        [ 0.4792, -0.3930,  0.0671,  ...,  0.5590,  0.0426, -0.1219]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.5417, -0.4509,  0.0800,  ...,  0.6563, -0.0553, -0.2540],\n",
      "        [ 0.5469, -0.4644,  0.1539,  ...,  0.6621, -0.0741, -0.2245],\n",
      "        [ 0.4819, -0.3489,  0.1097,  ...,  0.6291, -0.0895, -0.1218],\n",
      "        ...,\n",
      "        [ 0.0479, -0.2935,  0.1843,  ...,  0.4161,  0.0864,  0.0050],\n",
      "        [ 0.2914, -0.3780,  0.2378,  ...,  0.4821, -0.0350, -0.0667],\n",
      "        [ 0.4585, -0.4102,  0.0842,  ...,  0.5652,  0.0258, -0.1260]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "Iteration: 2; Percent complete: 0.0%; Average loss: 7.5626; Perplexity: 1924.90\n",
      "tensor([[ 0.9894,  0.1549, -0.3017,  ...,  0.9814,  0.5628,  0.1055],\n",
      "        [ 0.9952,  0.3860,  0.1341,  ...,  0.9936,  0.8029,  0.3876],\n",
      "        [ 0.9934,  0.2930, -0.1124,  ...,  0.9909,  0.6438,  0.3384],\n",
      "        ...,\n",
      "        [ 0.9205,  0.3652,  0.3472,  ...,  0.9318,  0.6358,  0.1508],\n",
      "        [ 0.9762,  0.2654,  0.3860,  ...,  0.9714,  0.5318,  0.2181],\n",
      "        [ 0.9923,  0.0772, -0.1982,  ...,  0.9893,  0.8328,  0.1997]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9965,  0.1685, -0.1366,  ...,  0.9962,  0.6207,  0.3108],\n",
      "        [ 0.9981,  0.3296,  0.1147,  ...,  0.9979,  0.8101,  0.5207],\n",
      "        [ 0.9978,  0.3050, -0.0755,  ...,  0.9973,  0.6900,  0.5362],\n",
      "        ...,\n",
      "        [ 0.9607,  0.3995,  0.4084,  ...,  0.9739,  0.6356,  0.3943],\n",
      "        [ 0.9905,  0.3665,  0.4856,  ...,  0.9899,  0.5948,  0.4274],\n",
      "        [ 0.9966,  0.1030, -0.1225,  ...,  0.9964,  0.8258,  0.4537]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9983,  0.2117, -0.0271,  ...,  0.9987,  0.6680,  0.4212],\n",
      "        [ 0.9988,  0.3058,  0.0866,  ...,  0.9988,  0.8039,  0.5430],\n",
      "        [ 0.9985,  0.2862, -0.1009,  ...,  0.9984,  0.6660,  0.6240],\n",
      "        ...,\n",
      "        [ 0.9739,  0.3619,  0.4301,  ...,  0.9833,  0.6335,  0.4685],\n",
      "        [ 0.9934,  0.3616,  0.5181,  ...,  0.9940,  0.5985,  0.5262],\n",
      "        [ 0.9977,  0.1310, -0.0618,  ...,  0.9979,  0.8161,  0.5039]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9989,  0.2293,  0.0167,  ...,  0.9991,  0.6963,  0.4806],\n",
      "        [ 0.9990,  0.2834,  0.1335,  ...,  0.9990,  0.7996,  0.5315],\n",
      "        [ 0.9987,  0.3200, -0.1364,  ...,  0.9987,  0.6706,  0.6275],\n",
      "        ...,\n",
      "        [ 0.9831,  0.3586,  0.4336,  ...,  0.9891,  0.6223,  0.4705],\n",
      "        [ 0.9940,  0.3816,  0.4924,  ...,  0.9954,  0.5794,  0.5455],\n",
      "        [ 0.9982,  0.1209, -0.0442,  ...,  0.9984,  0.8129,  0.5030]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9992,  0.2237, -0.0061,  ...,  0.9993,  0.7321,  0.4782],\n",
      "        [ 0.9991,  0.2962,  0.1512,  ...,  0.9992,  0.8105,  0.5399],\n",
      "        [ 0.9988,  0.3222, -0.1432,  ...,  0.9989,  0.6698,  0.6537],\n",
      "        ...,\n",
      "        [ 0.9850,  0.3878,  0.4563,  ...,  0.9901,  0.6065,  0.4755],\n",
      "        [ 0.9948,  0.4008,  0.5089,  ...,  0.9957,  0.6151,  0.5222],\n",
      "        [ 0.9984,  0.1343, -0.0297,  ...,  0.9987,  0.8118,  0.5117]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9992,  0.2702,  0.0319,  ...,  0.9994,  0.7434,  0.5203],\n",
      "        [ 0.9992,  0.2832,  0.1685,  ...,  0.9993,  0.7929,  0.5319],\n",
      "        [ 0.9990,  0.3488, -0.0974,  ...,  0.9989,  0.6844,  0.6089],\n",
      "        ...,\n",
      "        [ 0.9862,  0.3978,  0.4602,  ...,  0.9904,  0.6078,  0.4950],\n",
      "        [ 0.9951,  0.4186,  0.5338,  ...,  0.9960,  0.5781,  0.5407],\n",
      "        [ 0.9986,  0.1581,  0.0120,  ...,  0.9987,  0.8172,  0.5007]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.2654,  0.0479,  ...,  0.9994,  0.7493,  0.5071],\n",
      "        [ 0.9992,  0.3323,  0.1427,  ...,  0.9992,  0.8061,  0.5290],\n",
      "        [ 0.9990,  0.3717, -0.0934,  ...,  0.9990,  0.6968,  0.6044],\n",
      "        ...,\n",
      "        [ 0.9876,  0.4175,  0.4571,  ...,  0.9908,  0.5884,  0.4946],\n",
      "        [ 0.9952,  0.4252,  0.5663,  ...,  0.9959,  0.6022,  0.5407],\n",
      "        [ 0.9987,  0.1768,  0.0408,  ...,  0.9987,  0.8018,  0.4939]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.2607,  0.0689,  ...,  0.9994,  0.7551,  0.5091],\n",
      "        [ 0.9992,  0.3285,  0.0733,  ...,  0.9992,  0.7607,  0.5744],\n",
      "        [ 0.9990,  0.3541, -0.0765,  ...,  0.9990,  0.7013,  0.5881],\n",
      "        ...,\n",
      "        [ 0.9876,  0.4047,  0.4760,  ...,  0.9912,  0.5995,  0.4822],\n",
      "        [ 0.9953,  0.4827,  0.5415,  ...,  0.9958,  0.5541,  0.5363],\n",
      "        [ 0.9986,  0.2020,  0.0526,  ...,  0.9987,  0.7932,  0.5132]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.2779,  0.0806,  ...,  0.9994,  0.7613,  0.4896],\n",
      "        [ 0.9992,  0.3383,  0.0967,  ...,  0.9993,  0.7890,  0.5665],\n",
      "        [ 0.9990,  0.3969, -0.0725,  ...,  0.9989,  0.7233,  0.5952],\n",
      "        ...,\n",
      "        [ 0.9878,  0.4191,  0.4980,  ...,  0.9907,  0.6062,  0.4661],\n",
      "        [ 0.9953,  0.5060,  0.5484,  ...,  0.9959,  0.5502,  0.5521],\n",
      "        [ 0.9987,  0.1938,  0.0931,  ...,  0.9987,  0.7964,  0.4901]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.2850,  0.0761,  ...,  0.9995,  0.7474,  0.5001],\n",
      "        [ 0.9992,  0.3018,  0.1215,  ...,  0.9993,  0.7757,  0.5822],\n",
      "        [ 0.9990,  0.3464, -0.1432,  ...,  0.9990,  0.6993,  0.5994],\n",
      "        ...,\n",
      "        [ 0.9874,  0.3912,  0.4927,  ...,  0.9904,  0.5944,  0.5082],\n",
      "        [ 0.9952,  0.5050,  0.5436,  ...,  0.9961,  0.5539,  0.5295],\n",
      "        [ 0.9986,  0.2078,  0.1142,  ...,  0.9987,  0.8034,  0.5166]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9994,  0.2904,  0.0818,  ...,  0.9995,  0.7457,  0.5001],\n",
      "        [ 0.9992,  0.3286,  0.1351,  ...,  0.9992,  0.7733,  0.5685],\n",
      "        [ 0.9990,  0.3582, -0.0884,  ...,  0.9990,  0.6985,  0.6227],\n",
      "        ...,\n",
      "        [ 0.9890,  0.3963,  0.4898,  ...,  0.9914,  0.6044,  0.4727],\n",
      "        [ 0.9950,  0.5071,  0.5357,  ...,  0.9962,  0.5253,  0.5593],\n",
      "        [ 0.9987,  0.1864,  0.0887,  ...,  0.9989,  0.7975,  0.5137]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.2985,  0.0500,  ...,  0.9995,  0.7420,  0.5211],\n",
      "        [ 0.9991,  0.3600,  0.1501,  ...,  0.9993,  0.7596,  0.5961],\n",
      "        [ 0.9990,  0.3953, -0.1063,  ...,  0.9989,  0.6895,  0.6415],\n",
      "        ...,\n",
      "        [ 0.9887,  0.3917,  0.4876,  ...,  0.9916,  0.6174,  0.4826],\n",
      "        [ 0.9950,  0.5268,  0.5155,  ...,  0.9960,  0.5316,  0.5371],\n",
      "        [ 0.9986,  0.2100,  0.1249,  ...,  0.9988,  0.7820,  0.5354]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9995,  0.2700,  0.0405,  ...,  0.9995,  0.7624,  0.4715],\n",
      "        [ 0.9992,  0.3224,  0.1099,  ...,  0.9992,  0.7506,  0.5706],\n",
      "        [ 0.9990,  0.4176, -0.0899,  ...,  0.9989,  0.6805,  0.6288],\n",
      "        ...,\n",
      "        [ 0.9892,  0.4053,  0.4966,  ...,  0.9924,  0.6169,  0.4500],\n",
      "        [ 0.9956,  0.5159,  0.5436,  ...,  0.9960,  0.5416,  0.5214],\n",
      "        [ 0.9985,  0.2182,  0.1285,  ...,  0.9988,  0.7808,  0.5359]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.2994,  0.0776,  ...,  0.9994,  0.7644,  0.5232],\n",
      "        [ 0.9992,  0.3366,  0.0969,  ...,  0.9993,  0.7552,  0.5591],\n",
      "        [ 0.9991,  0.4167, -0.1041,  ...,  0.9990,  0.6894,  0.6174],\n",
      "        ...,\n",
      "        [ 0.9884,  0.4044,  0.5069,  ...,  0.9919,  0.6167,  0.4524],\n",
      "        [ 0.9952,  0.5205,  0.5622,  ...,  0.9959,  0.5442,  0.5028],\n",
      "        [ 0.9985,  0.2076,  0.1134,  ...,  0.9989,  0.7629,  0.5276]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.2842,  0.0608,  ...,  0.9994,  0.7850,  0.5047],\n",
      "        [ 0.9993,  0.3296,  0.0955,  ...,  0.9992,  0.7526,  0.5536],\n",
      "        [ 0.9990,  0.4112, -0.1422,  ...,  0.9990,  0.6796,  0.6569],\n",
      "        ...,\n",
      "        [ 0.9869,  0.4108,  0.4882,  ...,  0.9915,  0.5998,  0.5057],\n",
      "        [ 0.9953,  0.5063,  0.5488,  ...,  0.9960,  0.5509,  0.5212],\n",
      "        [ 0.9985,  0.2183,  0.1157,  ...,  0.9989,  0.7677,  0.5265]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.2740,  0.0895,  ...,  0.9994,  0.7941,  0.4920],\n",
      "        [ 0.9992,  0.3500,  0.0956,  ...,  0.9993,  0.7407,  0.5623],\n",
      "        [ 0.9990,  0.4343, -0.1204,  ...,  0.9990,  0.6874,  0.6051],\n",
      "        ...,\n",
      "        [ 0.9877,  0.4142,  0.4853,  ...,  0.9919,  0.6374,  0.5013],\n",
      "        [ 0.9955,  0.5029,  0.5438,  ...,  0.9962,  0.5274,  0.5056],\n",
      "        [ 0.9985,  0.2195,  0.0941,  ...,  0.9988,  0.7521,  0.5167]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.2783,  0.0149,  ...,  0.9995,  0.7779,  0.5351],\n",
      "        [ 0.9992,  0.3574,  0.1225,  ...,  0.9993,  0.7482,  0.5504],\n",
      "        [ 0.9990,  0.4127, -0.1164,  ...,  0.9990,  0.6589,  0.6197],\n",
      "        ...,\n",
      "        [ 0.9880,  0.4037,  0.4979,  ...,  0.9921,  0.6283,  0.4743],\n",
      "        [ 0.9953,  0.4948,  0.5441,  ...,  0.9963,  0.5496,  0.4973],\n",
      "        [ 0.9986,  0.2132,  0.0719,  ...,  0.9989,  0.7790,  0.5117]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.2790, -0.0191,  ...,  0.9994,  0.7818,  0.5210],\n",
      "        [ 0.9992,  0.3502,  0.0975,  ...,  0.9993,  0.7483,  0.5407],\n",
      "        [ 0.9990,  0.4254, -0.1494,  ...,  0.9990,  0.6781,  0.5956],\n",
      "        ...,\n",
      "        [ 0.9884,  0.3877,  0.4790,  ...,  0.9924,  0.6208,  0.4862],\n",
      "        [ 0.9955,  0.4768,  0.5573,  ...,  0.9965,  0.5560,  0.5208],\n",
      "        [ 0.9986,  0.2232,  0.0661,  ...,  0.9987,  0.7644,  0.5297]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.3039,  0.0112,  ...,  0.9995,  0.7702,  0.5279],\n",
      "        [ 0.9992,  0.4001,  0.1499,  ...,  0.9993,  0.7576,  0.5378],\n",
      "        [ 0.9989,  0.4309, -0.1137,  ...,  0.9991,  0.6749,  0.5992],\n",
      "        ...,\n",
      "        [ 0.9889,  0.3820,  0.4875,  ...,  0.9920,  0.6209,  0.4806],\n",
      "        [ 0.9956,  0.5036,  0.5555,  ...,  0.9963,  0.5482,  0.5127],\n",
      "        [ 0.9986,  0.1946,  0.0958,  ...,  0.9988,  0.7691,  0.5699]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9994,  0.3226,  0.0375,  ...,  0.9995,  0.7681,  0.5338],\n",
      "        [ 0.9992,  0.3824,  0.0840,  ...,  0.9993,  0.7331,  0.5544],\n",
      "        [ 0.9990,  0.4202, -0.0877,  ...,  0.9990,  0.6890,  0.5924],\n",
      "        ...,\n",
      "        [ 0.9884,  0.4110,  0.4862,  ...,  0.9920,  0.5968,  0.4743],\n",
      "        [ 0.9955,  0.4884,  0.5579,  ...,  0.9961,  0.5621,  0.5015],\n",
      "        [ 0.9986,  0.2260,  0.1336,  ...,  0.9988,  0.7679,  0.5129]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.2917,  0.0474,  ...,  0.9994,  0.7605,  0.4849],\n",
      "        [ 0.9992,  0.3722,  0.1250,  ...,  0.9993,  0.7351,  0.5476],\n",
      "        [ 0.9990,  0.4225, -0.0696,  ...,  0.9990,  0.7006,  0.5861],\n",
      "        ...,\n",
      "        [ 0.9878,  0.4213,  0.4883,  ...,  0.9915,  0.5858,  0.4637],\n",
      "        [ 0.9953,  0.5046,  0.5582,  ...,  0.9962,  0.5319,  0.4979],\n",
      "        [ 0.9986,  0.2437,  0.1413,  ...,  0.9988,  0.7826,  0.4851]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9992,  0.2959,  0.0190,  ...,  0.9994,  0.7513,  0.5385],\n",
      "        [ 0.9992,  0.3555,  0.0980,  ...,  0.9993,  0.7472,  0.5448],\n",
      "        [ 0.9990,  0.4352, -0.0831,  ...,  0.9990,  0.6822,  0.6050],\n",
      "        ...,\n",
      "        [ 0.9875,  0.4183,  0.5108,  ...,  0.9918,  0.5749,  0.4792],\n",
      "        [ 0.9954,  0.4949,  0.5646,  ...,  0.9963,  0.5673,  0.4906],\n",
      "        [ 0.9986,  0.2145,  0.1675,  ...,  0.9988,  0.7652,  0.5110]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.9993,  0.3134,  0.0230,  ...,  0.9994,  0.7520,  0.5232],\n",
      "        [ 0.9991,  0.3389,  0.1239,  ...,  0.9993,  0.7503,  0.5592],\n",
      "        [ 0.9990,  0.4403, -0.0962,  ...,  0.9991,  0.6692,  0.6021],\n",
      "        ...,\n",
      "        [ 0.9877,  0.4456,  0.5507,  ...,  0.9911,  0.6012,  0.4684],\n",
      "        [ 0.9954,  0.4932,  0.5470,  ...,  0.9964,  0.5448,  0.4875],\n",
      "        [ 0.9985,  0.2237,  0.1185,  ...,  0.9988,  0.7586,  0.5308]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "Iteration: 3; Percent complete: 0.0%; Average loss: 5.5002; Perplexity: 244.75\n",
      "tensor([[ 0.9987, -0.7365,  0.5753,  ...,  0.9953,  0.8141, -0.8930],\n",
      "        [ 1.0000, -0.8757,  0.9113,  ...,  0.9999,  0.9770, -0.9151],\n",
      "        [ 0.9999, -0.9121,  0.8306,  ...,  0.9999,  0.9568, -0.9256],\n",
      "        ...,\n",
      "        [ 0.9953, -0.4599,  0.8550,  ...,  0.9953,  0.9135, -0.6953],\n",
      "        [ 0.9997, -0.8091,  0.9016,  ...,  0.9992,  0.8955, -0.8746],\n",
      "        [ 0.9999, -0.9136,  0.6809,  ...,  0.9998,  0.9769, -0.9188]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9159,  0.7167,  ...,  0.9999,  0.9243, -0.9576],\n",
      "        [ 1.0000, -0.9562,  0.9005,  ...,  1.0000,  0.9706, -0.9602],\n",
      "        [ 1.0000, -0.9686,  0.8352,  ...,  1.0000,  0.9578, -0.9632],\n",
      "        ...,\n",
      "        [ 0.9991, -0.7612,  0.8614,  ...,  0.9989,  0.9085, -0.8144],\n",
      "        [ 0.9999, -0.9099,  0.9153,  ...,  0.9998,  0.9107, -0.9238],\n",
      "        [ 1.0000, -0.9602,  0.7181,  ...,  1.0000,  0.9738, -0.9585]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9603,  0.7986,  ...,  1.0000,  0.9470, -0.9759],\n",
      "        [ 1.0000, -0.9720,  0.8833,  ...,  1.0000,  0.9639, -0.9738],\n",
      "        [ 1.0000, -0.9781,  0.8352,  ...,  1.0000,  0.9548, -0.9763],\n",
      "        ...,\n",
      "        [ 0.9996, -0.8439,  0.8648,  ...,  0.9994,  0.8987, -0.8689],\n",
      "        [ 1.0000, -0.9366,  0.9172,  ...,  0.9999,  0.9059, -0.9479],\n",
      "        [ 1.0000, -0.9734,  0.7220,  ...,  1.0000,  0.9680, -0.9712]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9765,  0.8285,  ...,  1.0000,  0.9537, -0.9828],\n",
      "        [ 1.0000, -0.9782,  0.8818,  ...,  1.0000,  0.9603, -0.9805],\n",
      "        [ 1.0000, -0.9825,  0.8141,  ...,  1.0000,  0.9498, -0.9800],\n",
      "        ...,\n",
      "        [ 0.9997, -0.8771,  0.8597,  ...,  0.9996,  0.8820, -0.8996],\n",
      "        [ 1.0000, -0.9457,  0.9203,  ...,  0.9999,  0.8956, -0.9605],\n",
      "        [ 1.0000, -0.9790,  0.7459,  ...,  1.0000,  0.9652, -0.9786]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9817,  0.8429,  ...,  1.0000,  0.9552, -0.9850],\n",
      "        [ 1.0000, -0.9808,  0.8752,  ...,  1.0000,  0.9577, -0.9841],\n",
      "        [ 1.0000, -0.9842,  0.8186,  ...,  1.0000,  0.9515, -0.9833],\n",
      "        ...,\n",
      "        [ 0.9997, -0.8890,  0.8637,  ...,  0.9996,  0.8818, -0.9165],\n",
      "        [ 1.0000, -0.9487,  0.9267,  ...,  0.9999,  0.8940, -0.9663],\n",
      "        [ 1.0000, -0.9812,  0.7609,  ...,  1.0000,  0.9625, -0.9814]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9846,  0.8560,  ...,  1.0000,  0.9543, -0.9870],\n",
      "        [ 1.0000, -0.9821,  0.8838,  ...,  1.0000,  0.9549, -0.9857],\n",
      "        [ 1.0000, -0.9853,  0.8314,  ...,  1.0000,  0.9495, -0.9840],\n",
      "        ...,\n",
      "        [ 0.9997, -0.8973,  0.8670,  ...,  0.9997,  0.8783, -0.9213],\n",
      "        [ 1.0000, -0.9492,  0.9293,  ...,  0.9999,  0.8927, -0.9682],\n",
      "        [ 1.0000, -0.9827,  0.7749,  ...,  1.0000,  0.9603, -0.9831]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9854,  0.8735,  ...,  1.0000,  0.9561, -0.9878],\n",
      "        [ 1.0000, -0.9837,  0.8851,  ...,  1.0000,  0.9554, -0.9858],\n",
      "        [ 1.0000, -0.9858,  0.8327,  ...,  1.0000,  0.9538, -0.9854],\n",
      "        ...,\n",
      "        [ 0.9997, -0.9040,  0.8682,  ...,  0.9997,  0.8756, -0.9238],\n",
      "        [ 1.0000, -0.9503,  0.9338,  ...,  0.9999,  0.8910, -0.9704],\n",
      "        [ 1.0000, -0.9832,  0.7946,  ...,  1.0000,  0.9623, -0.9834]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000, -0.9857,  0.8730,  ...,  1.0000,  0.9535, -0.9878],\n",
      "        [ 1.0000, -0.9845,  0.8877,  ...,  1.0000,  0.9545, -0.9864],\n",
      "        [ 1.0000, -0.9866,  0.8234,  ...,  1.0000,  0.9479, -0.9868],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9118,  0.8781,  ...,  0.9997,  0.8749, -0.9312],\n",
      "        [ 1.0000, -0.9507,  0.9335,  ...,  0.9999,  0.8938, -0.9719],\n",
      "        [ 1.0000, -0.9843,  0.8064,  ...,  1.0000,  0.9578, -0.9844]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9866,  0.8804,  ...,  1.0000,  0.9533, -0.9890],\n",
      "        [ 1.0000, -0.9845,  0.8908,  ...,  1.0000,  0.9534, -0.9876],\n",
      "        [ 1.0000, -0.9870,  0.8282,  ...,  1.0000,  0.9449, -0.9873],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9114,  0.8780,  ...,  0.9997,  0.8717, -0.9347],\n",
      "        [ 1.0000, -0.9518,  0.9358,  ...,  0.9999,  0.8839, -0.9722],\n",
      "        [ 1.0000, -0.9840,  0.8180,  ...,  1.0000,  0.9575, -0.9850]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9872,  0.8843,  ...,  1.0000,  0.9504, -0.9897],\n",
      "        [ 1.0000, -0.9858,  0.8914,  ...,  1.0000,  0.9499, -0.9869],\n",
      "        [ 1.0000, -0.9869,  0.8377,  ...,  1.0000,  0.9447, -0.9878],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9155,  0.8752,  ...,  0.9997,  0.8700, -0.9377],\n",
      "        [ 1.0000, -0.9554,  0.9377,  ...,  1.0000,  0.8779, -0.9737],\n",
      "        [ 1.0000, -0.9836,  0.8310,  ...,  1.0000,  0.9575, -0.9857]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9881,  0.8865,  ...,  1.0000,  0.9535, -0.9901],\n",
      "        [ 1.0000, -0.9859,  0.9022,  ...,  1.0000,  0.9522, -0.9879],\n",
      "        [ 1.0000, -0.9863,  0.8442,  ...,  1.0000,  0.9464, -0.9884],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9162,  0.8830,  ...,  0.9997,  0.8707, -0.9411],\n",
      "        [ 1.0000, -0.9544,  0.9402,  ...,  1.0000,  0.8781, -0.9748],\n",
      "        [ 1.0000, -0.9843,  0.8373,  ...,  1.0000,  0.9573, -0.9856]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9877,  0.8899,  ...,  1.0000,  0.9489, -0.9894],\n",
      "        [ 1.0000, -0.9864,  0.8964,  ...,  1.0000,  0.9479, -0.9882],\n",
      "        [ 1.0000, -0.9867,  0.8468,  ...,  1.0000,  0.9458, -0.9885],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9187,  0.8782,  ...,  0.9997,  0.8657, -0.9414],\n",
      "        [ 1.0000, -0.9525,  0.9392,  ...,  1.0000,  0.8808, -0.9744],\n",
      "        [ 1.0000, -0.9848,  0.8336,  ...,  1.0000,  0.9561, -0.9859]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9879,  0.8975,  ...,  1.0000,  0.9458, -0.9902],\n",
      "        [ 1.0000, -0.9868,  0.8913,  ...,  1.0000,  0.9472, -0.9886],\n",
      "        [ 1.0000, -0.9868,  0.8470,  ...,  1.0000,  0.9499, -0.9891],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9142,  0.8873,  ...,  0.9997,  0.8724, -0.9428],\n",
      "        [ 1.0000, -0.9544,  0.9430,  ...,  1.0000,  0.8782, -0.9751],\n",
      "        [ 1.0000, -0.9853,  0.8347,  ...,  1.0000,  0.9539, -0.9860]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9882,  0.8971,  ...,  1.0000,  0.9493, -0.9903],\n",
      "        [ 1.0000, -0.9872,  0.8991,  ...,  1.0000,  0.9495, -0.9887],\n",
      "        [ 1.0000, -0.9869,  0.8585,  ...,  1.0000,  0.9495, -0.9893],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9210,  0.8843,  ...,  0.9998,  0.8693, -0.9446],\n",
      "        [ 1.0000, -0.9557,  0.9452,  ...,  1.0000,  0.8772, -0.9754],\n",
      "        [ 1.0000, -0.9850,  0.8358,  ...,  1.0000,  0.9527, -0.9862]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9882,  0.9006,  ...,  1.0000,  0.9493, -0.9906],\n",
      "        [ 1.0000, -0.9867,  0.9023,  ...,  1.0000,  0.9479, -0.9884],\n",
      "        [ 1.0000, -0.9872,  0.8530,  ...,  1.0000,  0.9468, -0.9889],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9188,  0.8877,  ...,  0.9998,  0.8630, -0.9456],\n",
      "        [ 1.0000, -0.9545,  0.9449,  ...,  1.0000,  0.8725, -0.9773],\n",
      "        [ 1.0000, -0.9849,  0.8479,  ...,  1.0000,  0.9519, -0.9864]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9884,  0.9051,  ...,  1.0000,  0.9512, -0.9906],\n",
      "        [ 1.0000, -0.9866,  0.8984,  ...,  1.0000,  0.9489, -0.9881],\n",
      "        [ 1.0000, -0.9875,  0.8506,  ...,  1.0000,  0.9429, -0.9891],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9200,  0.8928,  ...,  0.9998,  0.8647, -0.9455],\n",
      "        [ 1.0000, -0.9551,  0.9492,  ...,  1.0000,  0.8730, -0.9762],\n",
      "        [ 1.0000, -0.9856,  0.8478,  ...,  1.0000,  0.9532, -0.9869]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9878,  0.9071,  ...,  1.0000,  0.9516, -0.9907],\n",
      "        [ 1.0000, -0.9874,  0.9023,  ...,  1.0000,  0.9478, -0.9888],\n",
      "        [ 1.0000, -0.9872,  0.8602,  ...,  1.0000,  0.9464, -0.9891],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9238,  0.8922,  ...,  0.9998,  0.8673, -0.9476],\n",
      "        [ 1.0000, -0.9556,  0.9492,  ...,  1.0000,  0.8805, -0.9774],\n",
      "        [ 1.0000, -0.9857,  0.8487,  ...,  1.0000,  0.9537, -0.9869]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9881,  0.9070,  ...,  1.0000,  0.9515, -0.9911],\n",
      "        [ 1.0000, -0.9879,  0.9069,  ...,  1.0000,  0.9480, -0.9895],\n",
      "        [ 1.0000, -0.9875,  0.8568,  ...,  1.0000,  0.9444, -0.9888],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9226,  0.8937,  ...,  0.9998,  0.8616, -0.9509],\n",
      "        [ 1.0000, -0.9556,  0.9485,  ...,  1.0000,  0.8777, -0.9765],\n",
      "        [ 1.0000, -0.9855,  0.8550,  ...,  1.0000,  0.9537, -0.9870]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9877,  0.9078,  ...,  1.0000,  0.9539, -0.9916],\n",
      "        [ 1.0000, -0.9874,  0.9119,  ...,  1.0000,  0.9479, -0.9893],\n",
      "        [ 1.0000, -0.9876,  0.8585,  ...,  1.0000,  0.9435, -0.9892],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9255,  0.8966,  ...,  0.9998,  0.8615, -0.9492],\n",
      "        [ 1.0000, -0.9542,  0.9496,  ...,  1.0000,  0.8707, -0.9769],\n",
      "        [ 1.0000, -0.9860,  0.8568,  ...,  1.0000,  0.9506, -0.9885]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9885,  0.9004,  ...,  1.0000,  0.9481, -0.9915],\n",
      "        [ 1.0000, -0.9874,  0.9158,  ...,  1.0000,  0.9475, -0.9893],\n",
      "        [ 1.0000, -0.9879,  0.8597,  ...,  1.0000,  0.9424, -0.9897],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9249,  0.8992,  ...,  0.9998,  0.8689, -0.9490],\n",
      "        [ 1.0000, -0.9542,  0.9494,  ...,  1.0000,  0.8754, -0.9785],\n",
      "        [ 1.0000, -0.9861,  0.8540,  ...,  1.0000,  0.9502, -0.9874]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9884,  0.9095,  ...,  1.0000,  0.9499, -0.9913],\n",
      "        [ 1.0000, -0.9881,  0.9171,  ...,  1.0000,  0.9500, -0.9892],\n",
      "        [ 1.0000, -0.9879,  0.8624,  ...,  1.0000,  0.9446, -0.9898],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9236,  0.8985,  ...,  0.9998,  0.8705, -0.9512],\n",
      "        [ 1.0000, -0.9562,  0.9493,  ...,  1.0000,  0.8803, -0.9771],\n",
      "        [ 1.0000, -0.9858,  0.8600,  ...,  1.0000,  0.9506, -0.9868]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9888,  0.9101,  ...,  1.0000,  0.9493, -0.9918],\n",
      "        [ 1.0000, -0.9881,  0.9158,  ...,  1.0000,  0.9480, -0.9894],\n",
      "        [ 1.0000, -0.9878,  0.8644,  ...,  1.0000,  0.9440, -0.9894],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9268,  0.8981,  ...,  0.9998,  0.8657, -0.9532],\n",
      "        [ 1.0000, -0.9540,  0.9515,  ...,  1.0000,  0.8881, -0.9777],\n",
      "        [ 1.0000, -0.9853,  0.8674,  ...,  1.0000,  0.9522, -0.9877]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9889,  0.9087,  ...,  1.0000,  0.9519, -0.9910],\n",
      "        [ 1.0000, -0.9884,  0.9142,  ...,  1.0000,  0.9484, -0.9900],\n",
      "        [ 1.0000, -0.9879,  0.8543,  ...,  1.0000,  0.9441, -0.9895],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9259,  0.9001,  ...,  0.9998,  0.8631, -0.9527],\n",
      "        [ 1.0000, -0.9555,  0.9525,  ...,  1.0000,  0.8766, -0.9789],\n",
      "        [ 1.0000, -0.9852,  0.8693,  ...,  1.0000,  0.9521, -0.9874]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "Iteration: 4; Percent complete: 0.0%; Average loss: 5.1301; Perplexity: 169.03\n",
      "tensor([[ 1.0000, -0.9829,  0.8357,  ...,  1.0000,  0.8732, -0.9952],\n",
      "        [ 1.0000, -0.9849,  0.9629,  ...,  1.0000,  0.9814, -0.9961],\n",
      "        [ 1.0000, -0.9902,  0.9351,  ...,  1.0000,  0.9628, -0.9958],\n",
      "        ...,\n",
      "        [ 0.9988, -0.7527,  0.9494,  ...,  0.9988,  0.9377, -0.9332],\n",
      "        [ 1.0000, -0.9396,  0.9784,  ...,  0.9999,  0.9100, -0.9852],\n",
      "        [ 1.0000, -0.9904,  0.8710,  ...,  1.0000,  0.9821, -0.9956]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9966,  0.9156,  ...,  1.0000,  0.8961, -0.9990],\n",
      "        [ 1.0000, -0.9958,  0.9571,  ...,  1.0000,  0.9635, -0.9987],\n",
      "        [ 1.0000, -0.9971,  0.9350,  ...,  1.0000,  0.9448, -0.9986],\n",
      "        ...,\n",
      "        [ 0.9998, -0.9283,  0.9479,  ...,  0.9998,  0.9059, -0.9765],\n",
      "        [ 1.0000, -0.9775,  0.9798,  ...,  1.0000,  0.8886, -0.9943],\n",
      "        [ 1.0000, -0.9965,  0.8737,  ...,  1.0000,  0.9680, -0.9985]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9983,  0.9351,  ...,  1.0000,  0.8953, -0.9994],\n",
      "        [ 1.0000, -0.9972,  0.9530,  ...,  1.0000,  0.9538, -0.9991],\n",
      "        [ 1.0000, -0.9981,  0.9298,  ...,  1.0000,  0.9330, -0.9990],\n",
      "        ...,\n",
      "        [ 0.9999, -0.9529,  0.9455,  ...,  0.9999,  0.8778, -0.9840],\n",
      "        [ 1.0000, -0.9846,  0.9795,  ...,  1.0000,  0.8586, -0.9961],\n",
      "        [ 1.0000, -0.9975,  0.8809,  ...,  1.0000,  0.9591, -0.9989]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9987,  0.9399,  ...,  1.0000,  0.8877, -0.9995],\n",
      "        [ 1.0000, -0.9977,  0.9505,  ...,  1.0000,  0.9466, -0.9992],\n",
      "        [ 1.0000, -0.9985,  0.9285,  ...,  1.0000,  0.9302, -0.9992],\n",
      "        ...,\n",
      "        [ 0.9999, -0.9622,  0.9445,  ...,  0.9999,  0.8639, -0.9870],\n",
      "        [ 1.0000, -0.9868,  0.9798,  ...,  1.0000,  0.8461, -0.9968],\n",
      "        [ 1.0000, -0.9979,  0.8921,  ...,  1.0000,  0.9567, -0.9991]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000, -0.9989,  0.9470,  ...,  1.0000,  0.8925, -0.9996],\n",
      "        [ 1.0000, -0.9981,  0.9497,  ...,  1.0000,  0.9462, -0.9993],\n",
      "        [ 1.0000, -0.9986,  0.9282,  ...,  1.0000,  0.9297, -0.9993],\n",
      "        ...,\n",
      "        [ 0.9999, -0.9671,  0.9444,  ...,  0.9999,  0.8619, -0.9880],\n",
      "        [ 1.0000, -0.9878,  0.9800,  ...,  1.0000,  0.8498, -0.9972],\n",
      "        [ 1.0000, -0.9981,  0.8955,  ...,  1.0000,  0.9528, -0.9992]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9990,  0.9478,  ...,  1.0000,  0.8961, -0.9996],\n",
      "        [ 1.0000, -0.9982,  0.9502,  ...,  1.0000,  0.9455, -0.9993],\n",
      "        [ 1.0000, -0.9987,  0.9275,  ...,  1.0000,  0.9259, -0.9993],\n",
      "        ...,\n",
      "        [ 0.9999, -0.9697,  0.9452,  ...,  0.9999,  0.8556, -0.9893],\n",
      "        [ 1.0000, -0.9883,  0.9807,  ...,  1.0000,  0.8517, -0.9974],\n",
      "        [ 1.0000, -0.9982,  0.8956,  ...,  1.0000,  0.9494, -0.9992]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9991,  0.9436,  ...,  1.0000,  0.8929, -0.9996],\n",
      "        [ 1.0000, -0.9983,  0.9473,  ...,  1.0000,  0.9411, -0.9994],\n",
      "        [ 1.0000, -0.9988,  0.9259,  ...,  1.0000,  0.9285, -0.9994],\n",
      "        ...,\n",
      "        [ 0.9999, -0.9730,  0.9448,  ...,  0.9999,  0.8529, -0.9900],\n",
      "        [ 1.0000, -0.9895,  0.9811,  ...,  1.0000,  0.8493, -0.9976],\n",
      "        [ 1.0000, -0.9984,  0.8992,  ...,  1.0000,  0.9513, -0.9993]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9992,  0.9473,  ...,  1.0000,  0.8911, -0.9996],\n",
      "        [ 1.0000, -0.9985,  0.9479,  ...,  1.0000,  0.9412, -0.9994],\n",
      "        [ 1.0000, -0.9988,  0.9304,  ...,  1.0000,  0.9261, -0.9994],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9743,  0.9452,  ...,  1.0000,  0.8429, -0.9907],\n",
      "        [ 1.0000, -0.9898,  0.9814,  ...,  1.0000,  0.8442, -0.9977],\n",
      "        [ 1.0000, -0.9984,  0.9029,  ...,  1.0000,  0.9489, -0.9993]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9992,  0.9475,  ...,  1.0000,  0.8908, -0.9996],\n",
      "        [ 1.0000, -0.9986,  0.9461,  ...,  1.0000,  0.9389, -0.9995],\n",
      "        [ 1.0000, -0.9989,  0.9277,  ...,  1.0000,  0.9255, -0.9994],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9753,  0.9458,  ...,  1.0000,  0.8305, -0.9913],\n",
      "        [ 1.0000, -0.9897,  0.9815,  ...,  1.0000,  0.8386, -0.9978],\n",
      "        [ 1.0000, -0.9984,  0.9063,  ...,  1.0000,  0.9488, -0.9994]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9992,  0.9487,  ...,  1.0000,  0.8834, -0.9997],\n",
      "        [ 1.0000, -0.9986,  0.9503,  ...,  1.0000,  0.9406, -0.9995],\n",
      "        [ 1.0000, -0.9989,  0.9251,  ...,  1.0000,  0.9238, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9767,  0.9455,  ...,  1.0000,  0.8450, -0.9916],\n",
      "        [ 1.0000, -0.9901,  0.9826,  ...,  1.0000,  0.8356, -0.9979],\n",
      "        [ 1.0000, -0.9985,  0.9084,  ...,  1.0000,  0.9467, -0.9994]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9993,  0.9510,  ...,  1.0000,  0.8853, -0.9997],\n",
      "        [ 1.0000, -0.9987,  0.9495,  ...,  1.0000,  0.9385, -0.9995],\n",
      "        [ 1.0000, -0.9990,  0.9245,  ...,  1.0000,  0.9218, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9772,  0.9471,  ...,  1.0000,  0.8305, -0.9916],\n",
      "        [ 1.0000, -0.9904,  0.9837,  ...,  1.0000,  0.8334, -0.9979],\n",
      "        [ 1.0000, -0.9986,  0.9096,  ...,  1.0000,  0.9452, -0.9994]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9993,  0.9521,  ...,  1.0000,  0.8853, -0.9997],\n",
      "        [ 1.0000, -0.9987,  0.9498,  ...,  1.0000,  0.9382, -0.9995],\n",
      "        [ 1.0000, -0.9990,  0.9296,  ...,  1.0000,  0.9209, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9779,  0.9463,  ...,  1.0000,  0.8292, -0.9918],\n",
      "        [ 1.0000, -0.9908,  0.9836,  ...,  1.0000,  0.8299, -0.9979],\n",
      "        [ 1.0000, -0.9986,  0.9087,  ...,  1.0000,  0.9409, -0.9994]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9993,  0.9525,  ...,  1.0000,  0.8764, -0.9997],\n",
      "        [ 1.0000, -0.9988,  0.9489,  ...,  1.0000,  0.9347, -0.9995],\n",
      "        [ 1.0000, -0.9990,  0.9277,  ...,  1.0000,  0.9191, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9784,  0.9488,  ...,  1.0000,  0.8317, -0.9922],\n",
      "        [ 1.0000, -0.9907,  0.9831,  ...,  1.0000,  0.8249, -0.9980],\n",
      "        [ 1.0000, -0.9987,  0.9156,  ...,  1.0000,  0.9418, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9993,  0.9552,  ...,  1.0000,  0.8806, -0.9997],\n",
      "        [ 1.0000, -0.9988,  0.9510,  ...,  1.0000,  0.9363, -0.9995],\n",
      "        [ 1.0000, -0.9990,  0.9301,  ...,  1.0000,  0.9206, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9789,  0.9472,  ...,  1.0000,  0.8297, -0.9923],\n",
      "        [ 1.0000, -0.9906,  0.9838,  ...,  1.0000,  0.8229, -0.9981],\n",
      "        [ 1.0000, -0.9987,  0.9136,  ...,  1.0000,  0.9380, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9993,  0.9533,  ...,  1.0000,  0.8791, -0.9997],\n",
      "        [ 1.0000, -0.9988,  0.9484,  ...,  1.0000,  0.9333, -0.9995],\n",
      "        [ 1.0000, -0.9990,  0.9327,  ...,  1.0000,  0.9180, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9787,  0.9484,  ...,  1.0000,  0.8228, -0.9923],\n",
      "        [ 1.0000, -0.9909,  0.9843,  ...,  1.0000,  0.8134, -0.9981],\n",
      "        [ 1.0000, -0.9987,  0.9146,  ...,  1.0000,  0.9381, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9551,  ...,  1.0000,  0.8829, -0.9997],\n",
      "        [ 1.0000, -0.9989,  0.9502,  ...,  1.0000,  0.9339, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9294,  ...,  1.0000,  0.9142, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9791,  0.9484,  ...,  1.0000,  0.8177, -0.9927],\n",
      "        [ 1.0000, -0.9913,  0.9850,  ...,  1.0000,  0.8338, -0.9981],\n",
      "        [ 1.0000, -0.9987,  0.9183,  ...,  1.0000,  0.9430, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9555,  ...,  1.0000,  0.8712, -0.9997],\n",
      "        [ 1.0000, -0.9989,  0.9510,  ...,  1.0000,  0.9321, -0.9996],\n",
      "        [ 1.0000, -0.9990,  0.9299,  ...,  1.0000,  0.9195, -0.9995],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9799,  0.9516,  ...,  1.0000,  0.8337, -0.9930],\n",
      "        [ 1.0000, -0.9910,  0.9849,  ...,  1.0000,  0.8268, -0.9981],\n",
      "        [ 1.0000, -0.9987,  0.9190,  ...,  1.0000,  0.9418, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9554,  ...,  1.0000,  0.8687, -0.9997],\n",
      "        [ 1.0000, -0.9989,  0.9523,  ...,  1.0000,  0.9330, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9298,  ...,  1.0000,  0.9107, -0.9996],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9802,  0.9493,  ...,  1.0000,  0.8157, -0.9929],\n",
      "        [ 1.0000, -0.9912,  0.9849,  ...,  1.0000,  0.8206, -0.9981],\n",
      "        [ 1.0000, -0.9988,  0.9171,  ...,  1.0000,  0.9391, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9559,  ...,  1.0000,  0.8812, -0.9997],\n",
      "        [ 1.0000, -0.9989,  0.9507,  ...,  1.0000,  0.9285, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9305,  ...,  1.0000,  0.9107, -0.9996],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9803,  0.9498,  ...,  1.0000,  0.8263, -0.9930],\n",
      "        [ 1.0000, -0.9911,  0.9845,  ...,  1.0000,  0.8168, -0.9981],\n",
      "        [ 1.0000, -0.9988,  0.9211,  ...,  1.0000,  0.9335, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9568,  ...,  1.0000,  0.8809, -0.9997],\n",
      "        [ 1.0000, -0.9989,  0.9525,  ...,  1.0000,  0.9321, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9306,  ...,  1.0000,  0.9131, -0.9996],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9808,  0.9522,  ...,  1.0000,  0.8239, -0.9933],\n",
      "        [ 1.0000, -0.9913,  0.9852,  ...,  1.0000,  0.8246, -0.9982],\n",
      "        [ 1.0000, -0.9988,  0.9231,  ...,  1.0000,  0.9330, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9579,  ...,  1.0000,  0.8765, -0.9997],\n",
      "        [ 1.0000, -0.9989,  0.9512,  ...,  1.0000,  0.9323, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9295,  ...,  1.0000,  0.9078, -0.9996],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9816,  0.9513,  ...,  1.0000,  0.8178, -0.9931],\n",
      "        [ 1.0000, -0.9912,  0.9849,  ...,  1.0000,  0.8170, -0.9982],\n",
      "        [ 1.0000, -0.9988,  0.9257,  ...,  1.0000,  0.9334, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000, -0.9994,  0.9570,  ...,  1.0000,  0.8735, -0.9997],\n",
      "        [ 1.0000, -0.9990,  0.9533,  ...,  1.0000,  0.9305, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9344,  ...,  1.0000,  0.9103, -0.9996],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9805,  0.9530,  ...,  1.0000,  0.8202, -0.9933],\n",
      "        [ 1.0000, -0.9912,  0.9855,  ...,  1.0000,  0.8129, -0.9982],\n",
      "        [ 1.0000, -0.9989,  0.9220,  ...,  1.0000,  0.9314, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000, -0.9995,  0.9581,  ...,  1.0000,  0.8768, -0.9997],\n",
      "        [ 1.0000, -0.9990,  0.9512,  ...,  1.0000,  0.9294, -0.9996],\n",
      "        [ 1.0000, -0.9991,  0.9337,  ...,  1.0000,  0.9113, -0.9996],\n",
      "        ...,\n",
      "        [ 1.0000, -0.9817,  0.9516,  ...,  1.0000,  0.8135, -0.9932],\n",
      "        [ 1.0000, -0.9914,  0.9858,  ...,  1.0000,  0.7955, -0.9983],\n",
      "        [ 1.0000, -0.9989,  0.9255,  ...,  1.0000,  0.9350, -0.9995]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-191e8719c8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m trainIters(model_name, voc, pairs,pairs_emotion, encoder, decoder, encoder_optimizer, decoder_optimizer,\n\u001b[1;32m     26\u001b[0m            \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memotion_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m            print_every, save_every, clip,corpus_name,emotion_words)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-8d76b391bba7>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(model_name, voc, pairs, pairs_emotion, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, emotion_embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, external_memory)\u001b[0m\n\u001b[1;32m     37\u001b[0m                      \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memotion_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                      \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                      batch_size, clip)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print(loss_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-7c03bc6ad5f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, lengths, target_variable, target_variable_emotion, mask, max_target_len, encoder, decoder, embedding, emotion_embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Perform backpropatation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Clip gradients: gradients are modified in place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 5\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 2000000\n",
    "print_every = 1\n",
    "save_every = 2000\n",
    "\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs,pairs_emotion, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding,emotion_embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip,corpus_name,emotion_words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:45.602651Z",
     "start_time": "2019-04-03T00:20:12.272Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, emotions,max_length=MAX_LENGTH,beam_search = False):\n",
    "    emotions = int(emotions)\n",
    "    emotions = torch.LongTensor([emotions])\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    emotions = emotions.to(device)\n",
    "\n",
    "    # indexes -> words\n",
    "    if beam_search:\n",
    "        sequences = searcher(input_batch, emotions, lengths, max_length)\n",
    "        decoded_words = beam_decode(sequences,voc)\n",
    "    else:\n",
    "        # Decode sentence with searcher\n",
    "        tokens, scores = searcher(input_batch, emotions, lengths, max_length)\n",
    "        decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "def beam_decode(sequences,voc):\n",
    "    for each in sequences:\n",
    "        for idxs in each:\n",
    "            return [voc.index2word[idx] for idx in idxs[:-1]]\n",
    "    \n",
    "def evaluateInput(encoder, decoder, searcher, voc,emotion_dict,beam_search):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            for emotion in range(len(emotion_dict)):\n",
    "                # Check if it is quit case\n",
    "                if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "                # Normalize sentence\n",
    "                input_sentence = normalizeString(input_sentence)\n",
    "                # Evaluate sentence\n",
    "                output_words = evaluate(encoder, decoder, searcher, voc, input_sentence,emotion,beam_search=beam_search)\n",
    "                # Format and print response sentence\n",
    "                output=[]\n",
    "                for word in output_words:\n",
    "                    if word == 'PAD':\n",
    "                        continue\n",
    "                    elif word == 'EOS':\n",
    "                        break\n",
    "                    else:\n",
    "                        output.append(word)\n",
    "                print('Bot({}):'.format(emotion_dict[emotion]), ' '.join(output))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:20:45.603674Z",
     "start_time": "2019-04-03T00:20:12.276Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "searcher2 = BeamSearchDecoder(encoder,decoder,voc.num_words)\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc,emo_dict,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
