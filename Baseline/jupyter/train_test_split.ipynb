{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas \n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from preprocessing_dailydialogue import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/ecm/ecm_data1.pickle','rb') as f:\n",
    "    pairs = pickle.load(f)\n",
    "    pairs_emotion = pickle.load(f)\n",
    "    \n",
    "with open('../data/ecm/ecm_data2.pickle','rb') as f:\n",
    "    pairs2 = pickle.load(f)\n",
    "    pairs_emotion2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = pairs + pairs2\n",
    "pairs_emotion = pairs_emotion + pairs_emotion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = range(len(pairs))\n",
    "index_train = random.sample(index,303421)\n",
    "index = set(index) - set(index_train)\n",
    "index_test = random.sample(index,5000)\n",
    "index_val = list(set(index) - set(index_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train =[]\n",
    "train_emotion =[]\n",
    "for each in index_train:\n",
    "    train.append(pairs[each])\n",
    "    train_emotion.append(pairs_emotion[each])\n",
    "    \n",
    "test =[]\n",
    "test_emotion =[]\n",
    "for each in index_test:\n",
    "    test.append(pairs[each])\n",
    "    test_emotion.append(pairs_emotion[each])\n",
    "    \n",
    "val =[]\n",
    "val_emotion =[]\n",
    "for each in index_val:\n",
    "    val.append(pairs[each])\n",
    "    val_emotion.append(pairs_emotion[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.pickle','wb') as f:\n",
    "    pickle.dump(train,f)\n",
    "    pickle.dump(train_emotion,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.pickle','wb') as f:\n",
    "    pickle.dump(test,f)\n",
    "    pickle.dump(test_emotion,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('val.pickle','wb') as f:\n",
    "    pickle.dump(val,f)\n",
    "    pickle.dump(val_emotion,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('val.pickle','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "    b = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load from begining .\n",
    "# Default word tokens\n",
    "#\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "emo_dict = { 0: 'neutral', 1: 'joy', 2: 'anger', \n",
    "            3: 'sadness',4:'fear'}\n",
    "emo2idx = {value:key for key,value in emo_dict.items()}\n",
    "\n",
    "with open('../data/ecm/train.pickle','rb') as f:\n",
    "    pairs = pickle.load(f)\n",
    "    pairs_emotion = pickle.load(f)\n",
    "def process(pairs,pairs_emotion,voc = None,emo2idx = emo2idx):   \n",
    "    pairs_emotion_index = []\n",
    "    for each in pairs_emotion:\n",
    "        pairs_emotion_index.append([emo2idx[each[0]],emo2idx[each[1]]])\n",
    "    pairs_emotion = pairs_emotion_index\n",
    "    del pairs_emotion_index\n",
    "    if voc is None:\n",
    "        voc = Voc(name='train',max_length=MAX_LENGTH,min_count=MIN_COUNT)\n",
    "        print(len(pairs))\n",
    "        pairs,pairs_emotion = filterPairs(pairs,pairs_emotion,voc.max_length)\n",
    "        print(len(pairs),len(pairs_emotion))\n",
    "        for each in pairs:\n",
    "            voc.addSentence(each[0])\n",
    "            voc.addSentence(each[1])\n",
    "        print(len(pairs))\n",
    "    else:\n",
    "        pairs,pairs_emotion = filterPairs(pairs,pairs_emotion,voc.max_length)\n",
    "    pairs,pairs_emotion = trimRareWords(pairs=pairs,pairs_emotion=pairs_emotion,voc=voc,min_count=voc.min_count)\n",
    "    print(len(pairs),len(pairs_emotion))\n",
    "    \n",
    "    return pairs,pairs_emotion,voc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303421\n",
      "81873 81873\n",
      "81873\n",
      "keep_words 8848 / 19419 = 0.4556\n",
      "Trimmed from 81873 pairs to 70044, 0.8555 of total\n",
      "70044 70044\n"
     ]
    }
   ],
   "source": [
    "pairs,pairs_emotion,voc = process(pairs,pairs_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/ecm/test.pickle','rb') as f:\n",
    "    pairs_t = pickle.load(f)\n",
    "    pairs_emotion_t = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_t),len(pairs_emotion_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed from 1345 pairs to 1063, 0.7903 of total\n",
      "1063 1063\n"
     ]
    }
   ],
   "source": [
    "pairs_t,pairs_emotion_t,voc_t = process(pairs_t,pairs_emotion_t,voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes there was .', 'can you tell me what happened ?'], ['damone . it s mark .', 'mark . what happened to your date ?'], ['do i know you from somewhere ?', 'you may have known my father william starks .'], ['look .', 'you re almost one of us now michael .'], ['you should have gone at the restaurant .', 'i didn t have to pee then .']] [[2, 2], [2, 0], [4, 4], [4, 2], [4, 3]]\n",
      "[['i m running away .', 'you think that s wise ?'], ['can we see ?', 'you gonna buy ?'], ['i read the hospital report on your client .', '. . . deborah ann kaye . . .'], ['why the fuck not ?', 'just don t .'], ['what is it ? !', 'i don t know . wave to them !']] [[4, 0], [2, 4], [4, 2], [2, 4], [0, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:5],pairs_emotion[:5])\n",
    "print(pairs_t[:5],pairs_emotion_t[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 1063)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_t),len(pairs_emotion_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for each in pairs_t:\n",
    "    if len(each[0].split(' ')) >= voc.max_length:\n",
    "        print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('processed_train.pickle','wb') as f:\n",
    "    pickle.dump(pairs,f)\n",
    "    pickle.dump(pairs_emotion,f)\n",
    "    pickle.dump(voc,f)\n",
    "    \n",
    "with open('processed_test.pickle','wb') as f:\n",
    "    pickle.dump(pairs_t,f)\n",
    "    pickle.dump(pairs_emotion_t,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214361, 214361)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs),len(pairs_emotion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
