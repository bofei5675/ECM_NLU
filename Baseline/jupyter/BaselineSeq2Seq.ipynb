{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:31:51.765625Z",
     "start_time": "2019-04-07T23:31:51.420803Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "from preprocessing_dailydialogue import * \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "USE_CUDA = False #torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:31:52.603215Z",
     "start_time": "2019-04-07T23:31:52.595923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OpenSubtitlesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,txt_file, root_dir, transform = None,n = None):\n",
    "        self.txt_file = self.read_txt(txt_file,n = n)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform =transform\n",
    "    \n",
    "    def read_txt(self,txt_file,n = None):\n",
    "        dataset = []\n",
    "        count = 0\n",
    "        with open(txt_file,'r') as f:\n",
    "            conversation = []\n",
    "            for line in f:\n",
    "                count += 1\n",
    "                conversation.append(line.rstrip())\n",
    "                if len(conversation) == 2:\n",
    "                    dataset.append(conversation)\n",
    "                    conversation = []\n",
    "                if count == n:\n",
    "                    break\n",
    "            \n",
    "        print('Total converation {}'.format(count))\n",
    "        \n",
    "        return dataset\n",
    "    def trimRareWords(self,voc,min_count):\n",
    "        # Trim words used under the MIN_COUNT from the voc\n",
    "\n",
    "        voc.trim()\n",
    "        # Filter out pairs with trimmed words\n",
    "        keep_pairs = []\n",
    "        for pair in self.txt_file:\n",
    "            input_sentence = pair[0]\n",
    "            output_sentence = pair[1]\n",
    "            keep_input = True\n",
    "            keep_output = True\n",
    "            # Check input sentence\n",
    "            for word in input_sentence.split(' '):\n",
    "                if word not in voc.word2index:\n",
    "                    keep_input = False\n",
    "                    break\n",
    "            # Check output sentence\n",
    "            for word in output_sentence.split(' '):\n",
    "                if word not in voc.word2index:\n",
    "                    keep_output = False\n",
    "                    break\n",
    "\n",
    "            # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "            if keep_input and keep_output:\n",
    "                keep_pairs.append(pair)\n",
    "            \n",
    "        self.txt_file = keep_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('processed_train.pickle','rb') as f:\n",
    "    pairs = pickle.load(f)\n",
    "    pairs_emotion = pickle.load(f)\n",
    "    voc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:31:57.397467Z",
     "start_time": "2019-04-07T23:31:57.260189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[  77,   11,    3,  217, 6767],\n",
      "        [  16,   73,   56,  760,    6],\n",
      "        [ 169,    8,  601,   62,    2],\n",
      "        [  37,   24,    6,    6,    0],\n",
      "        [ 664,  100,    2,    2,    0],\n",
      "        [ 752,  324,    0,    0,    0],\n",
      "        [  56,   13,    0,    0,    0],\n",
      "        [   2,    2,    0,    0,    0]])\n",
      "lengths: tensor([8, 8, 5, 5, 3])\n",
      "target_variable: tensor([[  64,   37,  111,   11, 6767],\n",
      "        [  37,  205,   37,   73,   13],\n",
      "        [  91,  171, 6601,    8,    2],\n",
      "        [3329,   18,  415,  202,    0],\n",
      "        [   8,  418,   13,   85,    0],\n",
      "        [   6,   44,    2,   13,    0],\n",
      "        [   2, 2742,    0,    2,    0],\n",
      "        [   0,    6,    0,    0,    0],\n",
      "        [   0,    2,    0,    0,    0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:31:58.345967Z",
     "start_time": "2019-04-07T23:31:58.330001Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden\n",
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "    \n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden\n",
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:31:59.290254Z",
     "start_time": "2019-04-07T23:31:59.278957Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            print(decoder_output.shape)\n",
    "            print(decoder_output.topk(1))\n",
    "            time.sleep(3)\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            print(mask_loss.shape)\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:32:00.415350Z",
     "start_time": "2019-04-07T23:32:00.405647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "    print('Loading ...')\n",
    "    # Load batches for each iteration\n",
    "    #training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "    #                  for _ in range(n_iteration)]\n",
    "    print('Finish Loading ...')\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        # load each batch for each iteration\n",
    "        training_batch = batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip,voc.max_length)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            output = \"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg)\n",
    "            with open('/scratch/bz1030/log.txt','a+') as f:\n",
    "                f.write(output + '\\n')\n",
    "            print(output)\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T02:27:37.954118Z",
     "start_time": "2019-04-08T02:27:37.939676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BeamSearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder,num_word):\n",
    "        super(BeamSearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.num_word = num_word\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_words_order = torch.zeros((1,self.num_word),device=device,dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        all_scores_array = torch.zeros((1,self.num_word),device=device,dtype=torch.float)\n",
    "        # Set initial context value,last_rnn_output, internal_memory\n",
    "        # last_rnn_output = torch.FloatTensor(hidden_size)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            decoder_input_order = torch.argsort(decoder_output,dim=1,descending=True)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            all_scores_array = torch.cat((all_scores_array,decoder_output),dim = 0)\n",
    "            all_words_order = torch.cat((all_words_order,decoder_input_order), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        print('Start Beam Search')\n",
    "        sequences = self.beam_search(all_scores_array,3)\n",
    "        return sequences\n",
    "    def beam_search(self,array,k):\n",
    "        array = array.tolist()\n",
    "        sequences = [[list(), 1.0]]\n",
    "        # walk over each step in sequence\n",
    "        for row in array:\n",
    "            all_candidates = list()\n",
    "            # expand each current candidate\n",
    "            for i in range(len(sequences)):\n",
    "                seq, score = sequences[i]\n",
    "                for j in range(len(row)):\n",
    "                    candidate = [seq + [j], score * -np.log(row[j] + 1e-8)]\n",
    "                    all_candidates.append(candidate)\n",
    "            # order all candidates by score\n",
    "            ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "            # select k best\n",
    "            sequences = ordered[:k]\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:37:00.732597Z",
     "start_time": "2019-04-07T23:37:00.725301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:41:58.909737Z",
     "start_time": "2019-04-07T23:41:58.900337Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    \n",
    "    # indexes -> words\n",
    "    if isinstance(searcher,BeamSearchDecoder):\n",
    "        sequences = searcher(input_batch,lengths, max_length)\n",
    "        decoded_words = beam_decode(sequences,voc)\n",
    "    else:\n",
    "        # Decode sentence with searcher\n",
    "        tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "        decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "def beam_decode(sequences,voc):\n",
    "    sentences = []\n",
    "    for each in sequences:\n",
    "        sentences.append([voc.index2word[idx] for idx in each[0]])\n",
    "        if len(sentences) == 3:\n",
    "            return sentences\n",
    "    return sentences\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence,voc.max_length)\n",
    "            # Format and print response sentence\n",
    "            for each in output_words:\n",
    "                print('Bot:', ' '.join([x for x in each if not (x == 'EOS' or x == 'PAD' or x =='SOS')]))\n",
    "            #output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            #print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T02:25:52.310076Z",
     "start_time": "2019-04-08T02:25:51.943344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"/scratch/bz1030/\", \"save\")\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 128\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename,map_location='cpu')\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T02:25:54.586853Z",
     "start_time": "2019-04-08T02:25:54.388165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Loading ...\n",
      "Finish Loading ...\n",
      "Initializing ...\n",
      "Training...\n",
      "torch.Size([128, 8851])\n",
      "(tensor([[0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001]], grad_fn=<TopkBackward>), tensor([[6866],\n",
      "        [2717],\n",
      "        [ 847],\n",
      "        [5107],\n",
      "        [ 542],\n",
      "        [2823],\n",
      "        [7249],\n",
      "        [ 139],\n",
      "        [6223],\n",
      "        [3274],\n",
      "        [7249],\n",
      "        [6782],\n",
      "        [1222],\n",
      "        [5435],\n",
      "        [3293],\n",
      "        [ 856],\n",
      "        [ 487],\n",
      "        [5425],\n",
      "        [3590],\n",
      "        [ 551],\n",
      "        [1063],\n",
      "        [3334],\n",
      "        [6886],\n",
      "        [4550],\n",
      "        [ 212],\n",
      "        [2148],\n",
      "        [3792],\n",
      "        [8356],\n",
      "        [6017],\n",
      "        [2570],\n",
      "        [3861],\n",
      "        [2326],\n",
      "        [3861],\n",
      "        [ 806],\n",
      "        [3861],\n",
      "        [4550],\n",
      "        [3861],\n",
      "        [5147],\n",
      "        [3274],\n",
      "        [5964],\n",
      "        [6338],\n",
      "        [6886],\n",
      "        [2023],\n",
      "        [4390],\n",
      "        [3813],\n",
      "        [6309],\n",
      "        [6029],\n",
      "        [1271],\n",
      "        [2255],\n",
      "        [8733],\n",
      "        [2176],\n",
      "        [ 778],\n",
      "        [1326],\n",
      "        [5585],\n",
      "        [7931],\n",
      "        [4550],\n",
      "        [3861],\n",
      "        [ 605],\n",
      "        [8438],\n",
      "        [7562],\n",
      "        [7931],\n",
      "        [ 806],\n",
      "        [5936],\n",
      "        [6939],\n",
      "        [4451],\n",
      "        [7562],\n",
      "        [7267],\n",
      "        [6866],\n",
      "        [7784],\n",
      "        [5399],\n",
      "        [3463],\n",
      "        [2823],\n",
      "        [6886],\n",
      "        [ 336],\n",
      "        [4683],\n",
      "        [3971],\n",
      "        [6223],\n",
      "        [6431],\n",
      "        [1135],\n",
      "        [3464],\n",
      "        [ 336],\n",
      "        [2436],\n",
      "        [3876],\n",
      "        [2761],\n",
      "        [5953],\n",
      "        [ 440],\n",
      "        [7507],\n",
      "        [6228],\n",
      "        [6223],\n",
      "        [6174],\n",
      "        [3398],\n",
      "        [4550],\n",
      "        [7611],\n",
      "        [4637],\n",
      "        [3463],\n",
      "        [4683],\n",
      "        [8383],\n",
      "        [ 680],\n",
      "        [6762],\n",
      "        [3334],\n",
      "        [   9],\n",
      "        [1324],\n",
      "        [3861],\n",
      "        [6223],\n",
      "        [8700],\n",
      "        [6886],\n",
      "        [3686],\n",
      "        [ 212],\n",
      "        [4870],\n",
      "        [ 903],\n",
      "        [2910],\n",
      "        [ 680],\n",
      "        [8618],\n",
      "        [3861],\n",
      "        [5585],\n",
      "        [8618],\n",
      "        [7822],\n",
      "        [7856],\n",
      "        [4502],\n",
      "        [7822],\n",
      "        [5923],\n",
      "        [7656],\n",
      "        [8618],\n",
      "        [3463],\n",
      "        [6408],\n",
      "        [ 840],\n",
      "        [8699],\n",
      "        [3097]]))\n",
      "torch.Size([])\n",
      "torch.Size([128, 8851])\n",
      "(tensor([[0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001]], grad_fn=<TopkBackward>), tensor([[4502],\n",
      "        [6845],\n",
      "        [8729],\n",
      "        [2766],\n",
      "        [7577],\n",
      "        [2823],\n",
      "        [1055],\n",
      "        [ 139],\n",
      "        [6223],\n",
      "        [2823],\n",
      "        [1251],\n",
      "        [5144],\n",
      "        [1222],\n",
      "        [5435],\n",
      "        [4683],\n",
      "        [7822],\n",
      "        [ 263],\n",
      "        [6806],\n",
      "        [3590],\n",
      "        [2145],\n",
      "        [1924],\n",
      "        [3334],\n",
      "        [8641],\n",
      "        [ 351],\n",
      "        [2916],\n",
      "        [5549],\n",
      "        [7856],\n",
      "        [7067],\n",
      "        [8009],\n",
      "        [8732],\n",
      "        [3861],\n",
      "        [4577],\n",
      "        [3861],\n",
      "        [ 806],\n",
      "        [3861],\n",
      "        [2758],\n",
      "        [3861],\n",
      "        [2770],\n",
      "        [1387],\n",
      "        [6712],\n",
      "        [6338],\n",
      "        [6133],\n",
      "        [2023],\n",
      "        [6399],\n",
      "        [ 863],\n",
      "        [ 356],\n",
      "        [6029],\n",
      "        [8263],\n",
      "        [2255],\n",
      "        [6953],\n",
      "        [2176],\n",
      "        [7602],\n",
      "        [2493],\n",
      "        [1866],\n",
      "        [3861],\n",
      "        [6886],\n",
      "        [3293],\n",
      "        [ 605],\n",
      "        [3464],\n",
      "        [7562],\n",
      "        [4671],\n",
      "        [3876],\n",
      "        [6866],\n",
      "        [2102],\n",
      "        [ 680],\n",
      "        [7562],\n",
      "        [7267],\n",
      "        [6866],\n",
      "        [2217],\n",
      "        [5399],\n",
      "        [ 707],\n",
      "        [7926],\n",
      "        [5246],\n",
      "        [3334],\n",
      "        [3861],\n",
      "        [4174],\n",
      "        [7782],\n",
      "        [4551],\n",
      "        [7249],\n",
      "        [6174],\n",
      "        [3861],\n",
      "        [7602],\n",
      "        [3876],\n",
      "        [ 139],\n",
      "        [ 212],\n",
      "        [ 680],\n",
      "        [4418],\n",
      "        [7465],\n",
      "        [4173],\n",
      "        [2828],\n",
      "        [3398],\n",
      "        [ 784],\n",
      "        [7611],\n",
      "        [7926],\n",
      "        [4502],\n",
      "        [4683],\n",
      "        [2659],\n",
      "        [6338],\n",
      "        [6853],\n",
      "        [7249],\n",
      "        [7494],\n",
      "        [3633],\n",
      "        [3861],\n",
      "        [8618],\n",
      "        [3274],\n",
      "        [5246],\n",
      "        [8618],\n",
      "        [2779],\n",
      "        [4870],\n",
      "        [3463],\n",
      "        [4683],\n",
      "        [ 840],\n",
      "        [ 680],\n",
      "        [3861],\n",
      "        [4683],\n",
      "        [ 778],\n",
      "        [4683],\n",
      "        [2119],\n",
      "        [ 680],\n",
      "        [4683],\n",
      "        [4390],\n",
      "        [7656],\n",
      "        [8399],\n",
      "        [2779],\n",
      "        [6408],\n",
      "        [6399],\n",
      "        [8699],\n",
      "        [4683]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([128, 8851])\n",
      "(tensor([[0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001]], grad_fn=<TopkBackward>), tensor([[7057],\n",
      "        [6845],\n",
      "        [7267],\n",
      "        [2766],\n",
      "        [6221],\n",
      "        [2659],\n",
      "        [4021],\n",
      "        [ 139],\n",
      "        [5528],\n",
      "        [1678],\n",
      "        [4550],\n",
      "        [5144],\n",
      "        [7886],\n",
      "        [2451],\n",
      "        [6190],\n",
      "        [7822],\n",
      "        [2245],\n",
      "        [4550],\n",
      "        [5069],\n",
      "        [2781],\n",
      "        [2106],\n",
      "        [7824],\n",
      "        [8641],\n",
      "        [ 680],\n",
      "        [7476],\n",
      "        [8768],\n",
      "        [7856],\n",
      "        [5338],\n",
      "        [8009],\n",
      "        [8732],\n",
      "        [6655],\n",
      "        [1095],\n",
      "        [1367],\n",
      "        [7349],\n",
      "        [3861],\n",
      "        [3602],\n",
      "        [5176],\n",
      "        [2770],\n",
      "        [6874],\n",
      "        [7608],\n",
      "        [ 351],\n",
      "        [4512],\n",
      "        [6338],\n",
      "        [7057],\n",
      "        [ 863],\n",
      "        [3058],\n",
      "        [2112],\n",
      "        [6223],\n",
      "        [6939],\n",
      "        [4683],\n",
      "        [4671],\n",
      "        [3665],\n",
      "        [2493],\n",
      "        [6174],\n",
      "        [3861],\n",
      "        [ 186],\n",
      "        [6318],\n",
      "        [6338],\n",
      "        [8800],\n",
      "        [7267],\n",
      "        [3947],\n",
      "        [3876],\n",
      "        [ 334],\n",
      "        [8820],\n",
      "        [ 680],\n",
      "        [7562],\n",
      "        [3927],\n",
      "        [6399],\n",
      "        [4975],\n",
      "        [6847],\n",
      "        [4390],\n",
      "        [4375],\n",
      "        [5246],\n",
      "        [7249],\n",
      "        [8774],\n",
      "        [6892],\n",
      "        [7782],\n",
      "        [4028],\n",
      "        [2214],\n",
      "        [2557],\n",
      "        [3861],\n",
      "        [7602],\n",
      "        [ 657],\n",
      "        [ 139],\n",
      "        [6096],\n",
      "        [ 680],\n",
      "        [4418],\n",
      "        [6696],\n",
      "        [3453],\n",
      "        [2828],\n",
      "        [2446],\n",
      "        [ 784],\n",
      "        [3770],\n",
      "        [4286],\n",
      "        [7844],\n",
      "        [7656],\n",
      "        [2023],\n",
      "        [6338],\n",
      "        [3750],\n",
      "        [3097],\n",
      "        [7494],\n",
      "        [ 840],\n",
      "        [ 334],\n",
      "        [7602],\n",
      "        [8076],\n",
      "        [5246],\n",
      "        [2977],\n",
      "        [1429],\n",
      "        [2443],\n",
      "        [ 334],\n",
      "        [4302],\n",
      "        [7476],\n",
      "        [6338],\n",
      "        [3861],\n",
      "        [7507],\n",
      "        [ 707],\n",
      "        [7822],\n",
      "        [   9],\n",
      "        [ 680],\n",
      "        [7822],\n",
      "        [5078],\n",
      "        [6275],\n",
      "        [3453],\n",
      "        [2779],\n",
      "        [6176],\n",
      "        [3274],\n",
      "        [4637],\n",
      "        [ 759]]))\n",
      "torch.Size([])\n",
      "torch.Size([128, 8851])\n",
      "(tensor([[0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001]], grad_fn=<TopkBackward>), tensor([[7057],\n",
      "        [6845],\n",
      "        [7267],\n",
      "        [4390],\n",
      "        [ 549],\n",
      "        [4286],\n",
      "        [6190],\n",
      "        [4069],\n",
      "        [5528],\n",
      "        [2446],\n",
      "        [4550],\n",
      "        [5144],\n",
      "        [7886],\n",
      "        [7127],\n",
      "        [3732],\n",
      "        [3823],\n",
      "        [2245],\n",
      "        [7656],\n",
      "        [5907],\n",
      "        [2781],\n",
      "        [5147],\n",
      "        [7824],\n",
      "        [8641],\n",
      "        [4390],\n",
      "        [7476],\n",
      "        [8638],\n",
      "        [7856],\n",
      "        [8840],\n",
      "        [5662],\n",
      "        [7379],\n",
      "        [6599],\n",
      "        [1095],\n",
      "        [8820],\n",
      "        [7349],\n",
      "        [3721],\n",
      "        [2935],\n",
      "        [4342],\n",
      "        [7844],\n",
      "        [6874],\n",
      "        [7934],\n",
      "        [6174],\n",
      "        [4512],\n",
      "        [ 989],\n",
      "        [6399],\n",
      "        [1350],\n",
      "        [3058],\n",
      "        [3334],\n",
      "        [2443],\n",
      "        [6939],\n",
      "        [7497],\n",
      "        [ 989],\n",
      "        [7602],\n",
      "        [7934],\n",
      "        [5689],\n",
      "        [3861],\n",
      "        [3094],\n",
      "        [3293],\n",
      "        [5369],\n",
      "        [1215],\n",
      "        [7290],\n",
      "        [2823],\n",
      "        [3691],\n",
      "        [ 334],\n",
      "        [3892],\n",
      "        [3249],\n",
      "        [7267],\n",
      "        [3927],\n",
      "        [6399],\n",
      "        [4975],\n",
      "        [2781],\n",
      "        [ 982],\n",
      "        [7658],\n",
      "        [8305],\n",
      "        [3334],\n",
      "        [2781],\n",
      "        [3464],\n",
      "        [6456],\n",
      "        [4028],\n",
      "        [2214],\n",
      "        [2557],\n",
      "        [6744],\n",
      "        [7602],\n",
      "        [5078],\n",
      "        [ 139],\n",
      "        [ 263],\n",
      "        [ 680],\n",
      "        [5709],\n",
      "        [ 443],\n",
      "        [7917],\n",
      "        [2106],\n",
      "        [7658],\n",
      "        [4637],\n",
      "        [3770],\n",
      "        [4286],\n",
      "        [5155],\n",
      "        [3861],\n",
      "        [6471],\n",
      "        [ 840],\n",
      "        [2818],\n",
      "        [3097],\n",
      "        [ 577],\n",
      "        [ 784],\n",
      "        [4302],\n",
      "        [7602],\n",
      "        [2823],\n",
      "        [5117],\n",
      "        [2977],\n",
      "        [1429],\n",
      "        [2443],\n",
      "        [5801],\n",
      "        [ 623],\n",
      "        [7476],\n",
      "        [3774],\n",
      "        [ 334],\n",
      "        [8732],\n",
      "        [4390],\n",
      "        [4683],\n",
      "        [2023],\n",
      "        [5537],\n",
      "        [3094],\n",
      "        [5078],\n",
      "        [3030],\n",
      "        [6174],\n",
      "        [2690],\n",
      "        [3892],\n",
      "        [7656],\n",
      "        [2375],\n",
      "        [7822]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([128, 8851])\n",
      "(tensor([[0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001]], grad_fn=<TopkBackward>), tensor([[7057],\n",
      "        [6494],\n",
      "        [3441],\n",
      "        [3250],\n",
      "        [ 549],\n",
      "        [4286],\n",
      "        [8184],\n",
      "        [1925],\n",
      "        [2443],\n",
      "        [2569],\n",
      "        [5461],\n",
      "        [5144],\n",
      "        [7851],\n",
      "        [7127],\n",
      "        [7249],\n",
      "        [7822],\n",
      "        [2245],\n",
      "        [8296],\n",
      "        [5907],\n",
      "        [ 700],\n",
      "        [5147],\n",
      "        [ 119],\n",
      "        [8641],\n",
      "        [6399],\n",
      "        [7476],\n",
      "        [1429],\n",
      "        [4137],\n",
      "        [3674],\n",
      "        [1068],\n",
      "        [4983],\n",
      "        [3861],\n",
      "        [1095],\n",
      "        [4342],\n",
      "        [7267],\n",
      "        [3721],\n",
      "        [ 356],\n",
      "        [1102],\n",
      "        [7789],\n",
      "        [7267],\n",
      "        [7321],\n",
      "        [6174],\n",
      "        [8820],\n",
      "        [5079],\n",
      "        [3334],\n",
      "        [1996],\n",
      "        [1275],\n",
      "        [3334],\n",
      "        [2443],\n",
      "        [5235],\n",
      "        [5965],\n",
      "        [ 989],\n",
      "        [7602],\n",
      "        [4237],\n",
      "        [5689],\n",
      "        [5071],\n",
      "        [7006],\n",
      "        [3293],\n",
      "        [5527],\n",
      "        [7669],\n",
      "        [4368],\n",
      "        [8527],\n",
      "        [8568],\n",
      "        [5801],\n",
      "        [8507],\n",
      "        [3249],\n",
      "        [6268],\n",
      "        [3927],\n",
      "        [2828],\n",
      "        [3750],\n",
      "        [2781],\n",
      "        [ 982],\n",
      "        [7658],\n",
      "        [8305],\n",
      "        [7057],\n",
      "        [6228],\n",
      "        [8233],\n",
      "        [ 992],\n",
      "        [5105],\n",
      "        [7851],\n",
      "        [2557],\n",
      "        [ 334],\n",
      "        [7602],\n",
      "        [6223],\n",
      "        [ 139],\n",
      "        [ 263],\n",
      "        [3030],\n",
      "        [5709],\n",
      "        [4353],\n",
      "        [4398],\n",
      "        [2823],\n",
      "        [7658],\n",
      "        [8660],\n",
      "        [3770],\n",
      "        [ 356],\n",
      "        [2828],\n",
      "        [3861],\n",
      "        [7602],\n",
      "        [5027],\n",
      "        [2781],\n",
      "        [3030],\n",
      "        [4077],\n",
      "        [ 784],\n",
      "        [3861],\n",
      "        [ 707],\n",
      "        [6425],\n",
      "        [5117],\n",
      "        [4447],\n",
      "        [5047],\n",
      "        [7267],\n",
      "        [2069],\n",
      "        [4302],\n",
      "        [7476],\n",
      "        [6419],\n",
      "        [5801],\n",
      "        [8732],\n",
      "        [3129],\n",
      "        [4825],\n",
      "        [2023],\n",
      "        [7602],\n",
      "        [6277],\n",
      "        [1894],\n",
      "        [6619],\n",
      "        [6174],\n",
      "        [5078],\n",
      "        [3892],\n",
      "        [2828],\n",
      "        [2375],\n",
      "        [7313]]))\n",
      "torch.Size([])\n",
      "torch.Size([128, 8851])\n",
      "(tensor([[0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001],\n",
      "        [0.0001]], grad_fn=<TopkBackward>), tensor([[6408],\n",
      "        [6494],\n",
      "        [3441],\n",
      "        [4390],\n",
      "        [3821],\n",
      "        [4286],\n",
      "        [4580],\n",
      "        [6034],\n",
      "        [5155],\n",
      "        [1783],\n",
      "        [5461],\n",
      "        [5144],\n",
      "        [7851],\n",
      "        [ 376],\n",
      "        [8244],\n",
      "        [3823],\n",
      "        [2245],\n",
      "        [2290],\n",
      "        [1925],\n",
      "        [7512],\n",
      "        [3382],\n",
      "        [2828],\n",
      "        [4709],\n",
      "        [6399],\n",
      "        [7476],\n",
      "        [1429],\n",
      "        [7117],\n",
      "        [3674],\n",
      "        [5662],\n",
      "        [4983],\n",
      "        [3861],\n",
      "        [1756],\n",
      "        [2589],\n",
      "        [5113],\n",
      "        [3721],\n",
      "        [5399],\n",
      "        [4342],\n",
      "        [2770],\n",
      "        [8384],\n",
      "        [7321],\n",
      "        [ 967],\n",
      "        [7048],\n",
      "        [ 989],\n",
      "        [2828],\n",
      "        [5867],\n",
      "        [7307],\n",
      "        [3334],\n",
      "        [4068],\n",
      "        [6926],\n",
      "        [3756],\n",
      "        [6926],\n",
      "        [3665],\n",
      "        [7523],\n",
      "        [6277],\n",
      "        [1102],\n",
      "        [7425],\n",
      "        [3293],\n",
      "        [2358],\n",
      "        [7669],\n",
      "        [4368],\n",
      "        [4671],\n",
      "        [5087],\n",
      "        [3521],\n",
      "        [ 784],\n",
      "        [ 440],\n",
      "        [3188],\n",
      "        [1494],\n",
      "        [2828],\n",
      "        [4777],\n",
      "        [7965],\n",
      "        [5416],\n",
      "        [7658],\n",
      "        [8305],\n",
      "        [1682],\n",
      "        [6228],\n",
      "        [4346],\n",
      "        [ 577],\n",
      "        [5105],\n",
      "        [7851],\n",
      "        [2557],\n",
      "        [1901],\n",
      "        [5078],\n",
      "        [6223],\n",
      "        [4069],\n",
      "        [3311],\n",
      "        [3030],\n",
      "        [3130],\n",
      "        [5270],\n",
      "        [4964],\n",
      "        [2828],\n",
      "        [3502],\n",
      "        [5294],\n",
      "        [2635],\n",
      "        [ 356],\n",
      "        [4935],\n",
      "        [5325],\n",
      "        [7602],\n",
      "        [2781],\n",
      "        [2781],\n",
      "        [4716],\n",
      "        [6174],\n",
      "        [ 776],\n",
      "        [3861],\n",
      "        [3629],\n",
      "        [ 742],\n",
      "        [6886],\n",
      "        [ 263],\n",
      "        [5047],\n",
      "        [2443],\n",
      "        [1783],\n",
      "        [7497],\n",
      "        [4947],\n",
      "        [8462],\n",
      "        [5801],\n",
      "        [8732],\n",
      "        [1874],\n",
      "        [ 263],\n",
      "        [2023],\n",
      "        [7602],\n",
      "        [6277],\n",
      "        [5399],\n",
      "        [7048],\n",
      "        [7267],\n",
      "        [6946],\n",
      "        [1215],\n",
      "        [ 645],\n",
      "        [2116],\n",
      "        [8337]]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-de7d5195e4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n\u001b[1;32m     25\u001b[0m            \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m            print_every, save_every, clip, corpus_name, loadFilename)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f527821d21ee>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Run a training iteration with batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n\u001b[0;32m---> 24\u001b[0;31m                      decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip,voc.max_length)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f5cff9481da0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 2000000\n",
    "print_every = 2000\n",
    "save_every = 50000\n",
    "corpus_name ='OpenSubtitles'\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T02:31:28.397763Z",
     "start_time": "2019-04-08T02:27:43.398219Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = BeamSearchDecoder(encoder,decoder,voc.num_words)\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
